// Auto-generated by generate.py - DO NOT EDIT

export const SCRIPT_BASE = `# Windmill Script Writing Guide

## General Principles

- Scripts must export a main function (do not call it)
- Libraries are installed automatically - do not show installation instructions
- Credentials and configuration are stored in resources and passed as parameters
- The windmill client (\`wmill\`) provides APIs for interacting with the platform

## Function Naming

- Main function: \`main\` (or \`preprocessor\` for preprocessor scripts)
- Must be async for TypeScript variants

## Return Values

- Scripts can return any JSON-serializable value
- Return values become available to subsequent flow steps via \`results.step_id\`

## Preprocessor Scripts

Preprocessor scripts process raw trigger data from various sources (webhook, custom HTTP route, SQS, WebSocket, Kafka, NATS, MQTT, Postgres, or email) before passing it to the flow. This separates the trigger logic from the flow logic and keeps the auto-generated UI clean.

The returned object determines the parameter values passed to the flow.
e.g., \`{ b: 1, a: 2 }\` calls the flow with \`a = 2\` and \`b = 1\`, assuming the flow has two inputs called \`a\` and \`b\`.

The preprocessor receives a single parameter called \`event\`.
`;

export const FLOW_BASE = `# Windmill Flow Building Guide

The OpenFlow schema (openflow.openapi.yaml) is the source of truth for flow structure. Refer to OPENFLOW_SCHEMA for the complete type definitions.

## Reserved Module IDs

- \`failure\` - Reserved for failure handler module
- \`preprocessor\` - Reserved for preprocessor module
- \`Input\` - Reserved for flow input reference

## Module ID Rules

- Must be unique across the entire flow
- Use underscores, not spaces (e.g., \`fetch_data\` not \`fetch data\`)
- Use descriptive names that reflect the step's purpose

## Common Mistakes to Avoid

- Missing \`input_transforms\` - Rawscript parameters won't receive values without them
- Referencing future steps - \`results.step_id\` only works for steps that execute before the current one
- Duplicate module IDs - Each module ID must be unique in the flow

## Data Flow Between Steps

- \`flow_input.property\` - Access flow input parameters
- \`results.step_id\` - Access output from a previous step
- \`results.step_id.property\` - Access specific property from previous step output
- \`flow_input.iter.value\` - Current item when inside a for-loop
- \`flow_input.iter.index\` - Current index when inside a for-loop

## Input Transforms

Every rawscript module needs \`input_transforms\` to map function parameters to values:

Static transform (fixed value):
{"param_name": {"type": "static", "value": "fixed_string"}}

JavaScript transform (dynamic expression):
{"param_name": {"type": "javascript", "expr": "results.previous_step.data"}}

## Resource References

- For flow inputs: Use type \`"object"\` with format \`"resource-{type}"\` (e.g., \`"resource-postgresql"\`)
- For step inputs: Use static value \`"$res:path/to/resource"\`

## Failure Handler

Executes when any step fails. Has access to error details:
- \`error.message\` - Error message
- \`error.step_id\` - ID of failed step
- \`error.name\` - Error name
- \`error.stack\` - Stack trace
`;

export const SDK_TYPESCRIPT = `# TypeScript SDK (windmill-client)

Import: import * as wmill from 'windmill-client'

// Initialize the Windmill client with authentication token and base URL
setClient(token?: string, baseUrl?: string): void

// Create a client configuration from env variables
getWorkspace(): string

// Get a resource value by path
async getResource(path?: string, undefinedIfEmpty?: boolean): Promise<any>

// Get the true root job id
async getRootJobId(jobId?: string): Promise<string>

// @deprecated Use runScriptByPath or runScriptByHash instead
async runScript(path: string | null = null, hash_: string | null = null, args: Record<string, any> | null = null, verbose: boolean = false): Promise<any>

// Run a script synchronously by its path and wait for the result
async runScriptByPath(path: string, args: Record<string, any> | null = null, verbose: boolean = false): Promise<any>

// Run a script synchronously by its hash and wait for the result
async runScriptByHash(hash_: string, args: Record<string, any> | null = null, verbose: boolean = false): Promise<any>

// Append a text to the result stream
appendToResultStream(text: string): void

// Stream to the result stream
async streamResult(stream: AsyncIterable<string>): Promise<void>

// Run a flow synchronously by its path and wait for the result
async runFlow(path: string | null = null, args: Record<string, any> | null = null, verbose: boolean = false): Promise<any>

// Wait for a job to complete and return its result
async waitJob(jobId: string, verbose: boolean = false): Promise<any>

// Get the result of a completed job
async getResult(jobId: string): Promise<any>

// Get the result of a job if completed, or its current status
async getResultMaybe(jobId: string): Promise<any>

// @deprecated Use runScriptByPathAsync or runScriptByHashAsync instead
async runScriptAsync(path: string | null, hash_: string | null, args: Record<string, any> | null, scheduledInSeconds: number | null = null): Promise<string>

// Run a script asynchronously by its path
async runScriptByPathAsync(path: string, args: Record<string, any> | null = null, scheduledInSeconds: number | null = null): Promise<string>

// Run a script asynchronously by its hash
async runScriptByHashAsync(hash_: string, args: Record<string, any> | null = null, scheduledInSeconds: number | null = null): Promise<string>

// Run a flow asynchronously by its path
async runFlowAsync(path: string | null, args: Record<string, any> | null, scheduledInSeconds: number | null = null, // can only be set to false if this the job will be fully await and not concurrent with any other job // as otherwise the child flow and its own child will store their state in the parent job which will // lead to incorrectness and failures doNotTrackInParent: boolean = true): Promise<string>

// Resolve a resource value in case the default value was picked because the input payload was undefined
async resolveDefaultResource(obj: any): Promise<any>

// Get the state file path from environment variables
getStatePath(): string

// Set a resource value by path
async setResource(value: any, path?: string, initializeToTypeIfNotExist?: string): Promise<void>

// Set the state
async setInternalState(state: any): Promise<void>

// Set the state
async setState(state: any): Promise<void>

// Set the progress
async setProgress(percent: number, jobId?: any): Promise<void>

// Get the progress
async getProgress(jobId?: any): Promise<number | null>

// Set a flow user state
async setFlowUserState(key: string, value: any, errorIfNotPossible?: boolean): Promise<void>

// Get a flow user state
async getFlowUserState(key: string, errorIfNotPossible?: boolean): Promise<any>

// Get the internal state
async getInternalState(): Promise<any>

// Get the state shared across executions
async getState(): Promise<any>

// Get a variable by path
async getVariable(path: string): Promise<string>

// Set a variable by path, create if not exist
async setVariable(path: string, value: string, isSecretIfNotExist?: boolean, descriptionIfNotExist?: string): Promise<void>

// Build a PostgreSQL connection URL from a database resource
async databaseUrlFromResource(path: string): Promise<string>

// Get S3 client settings from a resource or workspace default
async denoS3LightClientSettings(s3_resource_path: string | undefined): Promise<DenoS3LightClientSettings>

// Persist a file to the S3 bucket. If the s3ResourcePath is undefined, it will default to the workspace S3 resource.
async writeS3File(s3object: S3Object | undefined, fileContent: string | Blob, s3ResourcePath: string | undefined = undefined, contentType: string | undefined = undefined, contentDisposition: string | undefined = undefined): Promise<S3Object>

// Sign S3 objects to be used by anonymous users in public apps
async signS3Objects(s3objects: S3Object[]): Promise<S3Object[]>

// Sign S3 object to be used by anonymous users in public apps
async signS3Object(s3object: S3Object): Promise<S3Object>

// Generate a presigned public URL for an array of S3 objects.
async getPresignedS3PublicUrls(s3Objects: S3Object[], { baseUrl }: { baseUrl?: string } = {}): Promise<string[]>

// Generate a presigned public URL for an S3 object. If the S3 object is not signed yet, it will be signed first.
async getPresignedS3PublicUrl(s3Objects: S3Object, { baseUrl }: { baseUrl?: string } = {}): Promise<string>

// Get URLs needed for resuming a flow after this step
async getResumeUrls(approver?: string): Promise<

// @deprecated use getResumeUrls instead
getResumeEndpoints(approver?: string): Promise<

// Get an OIDC jwt token for auth to external services (e.g: Vault, AWS) (ee only)
async getIdToken(audience: string, expiresIn?: number): Promise<string>

// Convert a base64-encoded string to Uint8Array
base64ToUint8Array(data: string): Uint8Array

// Convert a Uint8Array to base64-encoded string
uint8ArrayToBase64(arrayBuffer: Uint8Array): string

// Get email from workspace username
async usernameToEmail(username: string): Promise<string>

// Create a SQL template function for DuckDB/ducklake queries
ducklake(name: string = "main"): SqlTemplateFunction

async setSharedState(// state: any, // path = "state.json" //): Promise<void>

async getSharedState(path = "state.json"): Promise<any>

async polarsConnectionSettings(s3_resource_path: string | undefined): Promise<any>

async duckdbConnectionSettings(s3_resource_path: string | undefined): Promise<any>

async loadS3File(s3object: S3Object, s3ResourcePath: string | undefined = undefined): Promise<Uint8Array | undefined>

async loadS3FileStream(s3object: S3Object, s3ResourcePath: string | undefined = undefined): Promise<Blob | undefined>

async requestInteractiveSlackApproval({ slackResourcePath, channelId, message, approver, defaultArgsJson, dynamicEnumsJson, }: SlackApprovalOptions): Promise<void>

async requestInteractiveTeamsApproval({ teamName, channelName, message, approver, defaultArgsJson, dynamicEnumsJson, }: TeamsApprovalOptions): Promise<void>

parseS3Object(s3Object: S3Object): S3ObjectRecord

datatable(name: string = "main"): SqlTemplateFunction
`;

export const SDK_PYTHON = `# Python SDK (wmill)

Import: import wmill

def init_global_client(f)

def deprecate(in_favor_of: str)

# Get the current workspace ID.
def get_workspace() -> str

# Get the root job ID for a flow hierarchy.
def get_root_job_id(job_id: str | None = None) -> str

def get_version() -> str

# Create a script job and return its job ID.
def run_script_async(hash_or_path: str, args: Dict[str, Any] = None, scheduled_in_secs: int = None) -> str

# Create a flow job and return its job ID.
def run_flow_async(path: str, args: Dict[str, Any] = None, scheduled_in_secs: int = None, do_not_track_in_parent: bool = True) -> str

# Run a script synchronously by hash and return its result.
def run_script_sync(hash: str, args: Dict[str, Any] = None, verbose: bool = False, assert_result_is_not_none: bool = True, cleanup: bool = True, timeout: dt.timedelta = None) -> Any

# Create a script job by path and return its job ID.
def run_script_by_path_async(path: str, args: Dict[str, Any] = None, scheduled_in_secs: Union[None, int] = None) -> str

# Create a script job by hash and return its job ID.
def run_script_by_hash_async(hash_: str, args: Dict[str, Any] = None, scheduled_in_secs: Union[None, int] = None) -> str

# Run a script synchronously by path and return its result.
def run_script_by_path_sync(path: str, args: Dict[str, Any] = None, verbose: bool = False, assert_result_is_not_none: bool = True, cleanup: bool = True, timeout: dt.timedelta = None) -> Any

# Get a JWT token for the given audience for OIDC purposes to login into third parties like AWS, Vault, GCP, etc.
def get_id_token(audience: str) -> str

# Get the status of a job.
def get_job_status(job_id: str) -> JobStatus

# Get the result of a completed job.
def get_result(job_id: str, assert_result_is_not_none = True) -> Dict[str, Any]

# Convenient helpers that takes an S3 resource as input and returns the settings necessary to
def duckdb_connection_settings(s3_resource_path: str = '') -> DuckDbConnectionSettings

# Convenient helpers that takes an S3 resource as input and returns the settings necessary to
def polars_connection_settings(s3_resource_path: str = '') -> PolarsConnectionSettings

# Convenient helpers that takes an S3 resource as input and returns the settings necessary to
def boto3_connection_settings(s3_resource_path: str = '') -> Boto3ConnectionSettings

# Load the entire content of a file stored in S3 as bytes
def load_s3_file(s3object: S3Object | str, s3_resource_path: str | None = None) -> bytes

# Load the content of a file stored in S3
def load_s3_file_reader(s3object: S3Object | str, s3_resource_path: str | None = None) -> BufferedReader

# Upload a file to S3
def write_s3_file(s3object: S3Object | str | None, file_content: BufferedReader | bytes, s3_resource_path: str | None = None, content_type: str | None = None, content_disposition: str | None = None) -> S3Object

# Sign S3 objects to be used by anonymous users in public apps
def sign_s3_objects(s3_objects: list[S3Object | str]) -> list[S3Object]

# Sign S3 object to be used by anonymous users in public apps
def sign_s3_object(s3_object: S3Object | str) -> S3Object

# Generate presigned public URLs for an array of S3 objects.
def get_presigned_s3_public_urls(s3_objects: list[S3Object | str], base_url: str | None = None) -> list[str]

# Generate a presigned public URL for an S3 object.
def get_presigned_s3_public_url(s3_object: S3Object | str, base_url: str | None = None) -> str

# Returns the current user
def whoami() -> dict

# Get the state
def get_state() -> Any

# Get resource from Windmill
def get_resource(path: str, none_if_undefined: bool = False) -> dict | None

# Set the resource at a given path as a string, creating it if it does not exist
def set_resource(path: str, value: Any, resource_type: str = 'any') -> None

# List resources from Windmill workspace.
def list_resources(resource_type: str = None, page: int = None, per_page: int = None) -> list[dict]

# Set the state
def set_state(value: Any) -> None

# Set the progress
def set_progress(value: int, job_id: Optional[str] = None) -> None

# Get the progress
def get_progress(job_id: Optional[str] = None) -> Any

# Set the state in the shared folder using pickle
def set_shared_state_pickle(value: Any, path = 'state.pickle') -> None

# Get the state in the shared folder using pickle
def get_shared_state_pickle(path = 'state.pickle') -> Any

# Set the state in the shared folder using pickle
def set_shared_state(value: Any, path = 'state.json') -> None

# Get the state in the shared folder using pickle
def get_shared_state(path = 'state.json') -> None

# Returns the variable at a given path as a string
def get_variable(path: str) -> str

# Set the variable at a given path as a string, creating it if it does not exist
def set_variable(path: str, value: str, is_secret: bool = False) -> None

# Get the user state of a flow at a given key
def get_flow_user_state(key: str) -> Any

# Set the user state of a flow at a given key
def set_flow_user_state(key: str, value: Any) -> None

# Get the state resource path from environment.
def get_state_path() -> str

# Get URLs needed for resuming a flow after suspension.
def get_resume_urls(approver: str = None) -> dict

def request_interactive_slack_approval(slack_resource_path: str, channel_id: str, message: str = None, approver: str = None, default_args_json: dict = None, dynamic_enums_json: dict = None) -> None

# Send a message to a Microsoft Teams conversation.
def send_teams_message(conversation_id: str, text: str, success: bool, card_block: dict = None)

# Cancel a specific job by ID.
def cancel_job(job_id: str, reason: str = None) -> str

# Cancel currently running executions of the same script.
def cancel_running() -> dict

# Run script synchronously and return its result.
def run_script(path: str = None, hash_: str = None, args: dict = None, timeout: dt.timedelta | int | float = None, verbose: bool = False, cleanup: bool = True, assert_result_is_not_none: bool = True) -> Any

# Run script by path synchronously and return its result.
def run_script_by_path(path: str, args: dict = None, timeout: dt.timedelta | int | float = None, verbose: bool = False, cleanup: bool = True, assert_result_is_not_none: bool = True) -> Any

# Run script by hash synchronously and return its result.
def run_script_by_hash(hash_: str, args: dict = None, timeout: dt.timedelta | int | float = None, verbose: bool = False, cleanup: bool = True, assert_result_is_not_none: bool = True) -> Any

# Run a script on the current worker without creating a job
def run_inline_script_preview(content: str, language: str, args: dict = None) -> Any

# Get email from workspace username
def username_to_email(username: str) -> str

# Get a DataTable client for SQL queries.
def datatable(name: str = 'main') -> DataTableClient

# Get a DuckLake client for DuckDB queries.
def ducklake(name: str = 'main') -> DucklakeClient

# Decorator to mark a function as a workflow task.
def task(*args, **kwargs)

# Parse resource syntax from string.
def parse_resource_syntax(s: str) -> Optional[str]

# Parse S3 object from string or S3Object format.
def parse_s3_object(s3_object: S3Object | str) -> S3Object

# Parse variable syntax from string.
def parse_variable_syntax(s: str) -> Optional[str]

# Append a text to the result stream.
def append_to_result_stream(text: str) -> None

# Stream to the result stream.
def stream_result(stream) -> None

# DuckDB executor requires explicit argument types at declaration
def infer_sql_type(value) -> str

def get_mocked_api() -> Optional[dict]

# Get the HTTP client instance.
def get_client() -> httpx.Client

# Make an HTTP GET request to the Windmill API.
def get(endpoint, raise_for_status = True, **kwargs) -> httpx.Response

# Make an HTTP POST request to the Windmill API.
def post(endpoint, raise_for_status = True, **kwargs) -> httpx.Response

# Create a new authentication token.
def create_token(duration = dt.timedelta(days=1)) -> str

# Create a script job and return its job id.
def run_script_async(path: str = None, hash_: str = None, args: dict = None, scheduled_in_secs: int = None) -> str

# Create a script job by path and return its job id.
def run_script_by_path_async(path: str, args: dict = None, scheduled_in_secs: int = None) -> str

# Create a script job by hash and return its job id.
def run_script_by_hash_async(hash_: str, args: dict = None, scheduled_in_secs: int = None) -> str

# Create a flow job and return its job id.
def run_flow_async(path: str, args: dict = None, scheduled_in_secs: int = None, do_not_track_in_parent: bool = True) -> str

# Run script synchronously and return its result.
def run_script(path: str = None, hash_: str = None, args: dict = None, timeout: dt.timedelta | int | float | None = None, verbose: bool = False, cleanup: bool = True, assert_result_is_not_none: bool = False) -> Any

# Run script by path synchronously and return its result.
def run_script_by_path(path: str, args: dict = None, timeout: dt.timedelta | int | float | None = None, verbose: bool = False, cleanup: bool = True, assert_result_is_not_none: bool = False) -> Any

# Run script by hash synchronously and return its result.
def run_script_by_hash(hash_: str, args: dict = None, timeout: dt.timedelta | int | float | None = None, verbose: bool = False, cleanup: bool = True, assert_result_is_not_none: bool = False) -> Any

# Run a script on the current worker without creating a job
def run_inline_script_preview(content: str, language: str, args: dict = None) -> Any

# Wait for a job to complete and return its result.
def wait_job(job_id, timeout: dt.timedelta | int | float | None = None, verbose: bool = False, cleanup: bool = True, assert_result_is_not_none: bool = False)

# Cancel a specific job by ID.
def cancel_job(job_id: str, reason: str = None) -> str

# Cancel currently running executions of the same script.
def cancel_running() -> dict

# Get job details by ID.
def get_job(job_id: str) -> dict

# Get the root job ID for a flow hierarchy.
def get_root_job_id(job_id: str | None = None) -> dict

# Get an OIDC JWT token for authentication to external services.
def get_id_token(audience: str, expires_in: int | None = None) -> str

# Get the status of a job.
def get_job_status(job_id: str) -> JobStatus

# Get the result of a completed job.
def get_result(job_id: str, assert_result_is_not_none: bool = True) -> Any

# Get a variable value by path.
def get_variable(path: str) -> str

# Set a variable value by path, creating it if it doesn't exist.
def set_variable(path: str, value: str, is_secret: bool = False) -> None

# Get a resource value by path.
def get_resource(path: str, none_if_undefined: bool = False) -> dict | None

# Set a resource value by path, creating it if it doesn't exist.
def set_resource(value: Any, path: str, resource_type: str)

# List resources from Windmill workspace.
def list_resources(resource_type: str = None, page: int = None, per_page: int = None) -> list[dict]

# Set the workflow state.
def set_state(value: Any)

# Set job progress percentage (0-99).
def set_progress(value: int, job_id: Optional[str] = None)

# Get job progress percentage.
def get_progress(job_id: Optional[str] = None) -> Any

# Set the user state of a flow at a given key
def set_flow_user_state(key: str, value: Any) -> None

# Get the user state of a flow at a given key
def get_flow_user_state(key: str) -> Any

# Get the Windmill server version.
def version()

# Convenient helpers that takes an S3 resource as input and returns the settings necessary to
def get_duckdb_connection_settings(s3_resource_path: str = '') -> DuckDbConnectionSettings | None

# Convenient helpers that takes an S3 resource as input and returns the settings necessary to
def get_polars_connection_settings(s3_resource_path: str = '') -> PolarsConnectionSettings

# Convenient helpers that takes an S3 resource as input and returns the settings necessary to
def get_boto3_connection_settings(s3_resource_path: str = '') -> Boto3ConnectionSettings

# Load a file from the workspace s3 bucket and returns its content as bytes.
def load_s3_file(s3object: S3Object | str, s3_resource_path: str | None) -> bytes

# Load a file from the workspace s3 bucket and returns the bytes stream.
def load_s3_file_reader(s3object: S3Object | str, s3_resource_path: str | None) -> BufferedReader

# Write a file to the workspace S3 bucket
def write_s3_file(s3object: S3Object | str | None, file_content: BufferedReader | bytes, s3_resource_path: str | None, content_type: str | None = None, content_disposition: str | None = None) -> S3Object

# Sign S3 objects for use by anonymous users in public apps.
def sign_s3_objects(s3_objects: list[S3Object | str]) -> list[S3Object]

# Sign a single S3 object for use by anonymous users in public apps.
def sign_s3_object(s3_object: S3Object | str) -> S3Object

# Generate presigned public URLs for an array of S3 objects.
def get_presigned_s3_public_urls(s3_objects: list[S3Object | str], base_url: str | None = None) -> list[str]

# Generate a presigned public URL for an S3 object.
def get_presigned_s3_public_url(s3_object: S3Object | str, base_url: str | None = None) -> str

# Get the current user information.
def whoami() -> dict

# Get the current user information (alias for whoami).
def user() -> dict

# Get the state resource path from environment.
def state_path() -> str

# Get the workflow state.
def state() -> Any

# Set the workflow state.
def state(value: Any) -> None

# Set the state in the shared folder using pickle
def set_shared_state_pickle(value: Any, path: str = 'state.pickle') -> None

# Get the state in the shared folder using pickle
def get_shared_state_pickle(path: str = 'state.pickle') -> Any

# Set the state in the shared folder using pickle
def set_shared_state(value: Any, path: str = 'state.json') -> None

# Get the state in the shared folder using pickle
def get_shared_state(path: str = 'state.json') -> None

# Get URLs needed for resuming a flow after suspension.
def get_resume_urls(approver: str = None) -> dict

# Sends an interactive approval request via Slack, allowing optional customization of the message, approver, and form fields.
def request_interactive_slack_approval(slack_resource_path: str, channel_id: str, message: str = None, approver: str = None, default_args_json: dict = None, dynamic_enums_json: dict = None) -> None

# Get email from workspace username
def username_to_email(username: str) -> str

# Send a message to a Microsoft Teams conversation with conversation_id, where success is used to style the message
def send_teams_message(conversation_id: str, text: str, success: bool = True, card_block: dict = None)

# Get a DataTable client for SQL queries.
def datatable(name: str = 'main')

# Get a DuckLake client for DuckDB queries.
def ducklake(name: str = 'main')

def wrapper(*args, **kwargs)

def decorator(f)

def f(func, tag: str | None = None)

# Execute a SQL query against the DataTable.
def query(sql: str, *args)

# Execute a DuckDB query against the DuckLake database.
def query(sql: str, **kwargs)

# Execute query and fetch results.
def fetch(result_collection: str | None = None)

# Execute query and fetch first row of results.
def fetch_one()

def cancel_job()

def wrapper(*args, **kwargs)

def inner(*args, **kwargs)

def inner(*args, **kwargs)

`;

export const OPENFLOW_SCHEMA = `## OpenFlow Schema

{"OpenFlow":{"type":"object","description":"Top-level flow definition containing metadata, configuration, and the flow structure","properties":{"summary":{"type":"string","description":"Short description of what this flow does"},"description":{"type":"string","description":"Detailed documentation for this flow"},"value":{"$ref":"#/components/schemas/FlowValue"},"schema":{"type":"object","description":"JSON Schema for flow inputs. Use this to define input parameters, their types, defaults, and validation. For resource inputs, set type to 'object' and format to 'resource-<type>' (e.g., 'resource-stripe')"}},"required":["summary","value"]},"FlowValue":{"type":"object","description":"The flow structure containing modules and optional preprocessor/failure handlers","properties":{"modules":{"type":"array","description":"Array of steps that execute in sequence. Each step can be a script, subflow, loop, or branch","items":{"$ref":"#/components/schemas/FlowModule"}},"failure_module":{"description":"Special module that executes when the flow fails. Receives error object with message, name, stack, and step_id. Must have id 'failure'. Only supports script/rawscript types","$ref":"#/components/schemas/FlowModule"},"preprocessor_module":{"description":"Special module that runs before the first step on external triggers. Must have id 'preprocessor'. Only supports script/rawscript types. Cannot reference other step results","$ref":"#/components/schemas/FlowModule"},"same_worker":{"type":"boolean","description":"If true, all steps run on the same worker for better performance"},"concurrent_limit":{"type":"number","description":"Maximum number of concurrent executions of this flow"},"concurrency_key":{"type":"string","description":"Expression to group concurrent executions (e.g., by user ID)"},"concurrency_time_window_s":{"type":"number","description":"Time window in seconds for concurrent_limit"},"debounce_delay_s":{"type":"number","description":"Delay in seconds to debounce flow executions"},"debounce_key":{"type":"string","description":"Expression to group debounced executions"},"skip_expr":{"type":"string","description":"JavaScript expression to conditionally skip the entire flow"},"cache_ttl":{"type":"number","description":"Cache duration in seconds for flow results"},"cache_ignore_s3_path":{"type":"boolean"},"flow_env":{"type":"object","description":"Environment variables available to all steps","additionalProperties":{"type":"string"}},"priority":{"type":"number","description":"Execution priority (higher numbers run first)"},"early_return":{"type":"string","description":"JavaScript expression to return early from the flow"},"chat_input_enabled":{"type":"boolean","description":"Whether this flow accepts chat-style input"},"notes":{"type":"array","description":"Sticky notes attached to the flow","items":{"$ref":"#/components/schemas/FlowNote"}}},"required":["modules"]},"Retry":{"type":"object","description":"Retry configuration for failed module executions","properties":{"constant":{"type":"object","description":"Retry with constant delay between attempts","properties":{"attempts":{"type":"integer","description":"Number of retry attempts"},"seconds":{"type":"integer","description":"Seconds to wait between retries"}}},"exponential":{"type":"object","description":"Retry with exponential backoff (delay doubles each time)","properties":{"attempts":{"type":"integer","description":"Number of retry attempts"},"multiplier":{"type":"integer","description":"Multiplier for exponential backoff"},"seconds":{"type":"integer","minimum":1,"description":"Initial delay in seconds"},"random_factor":{"type":"integer","minimum":0,"maximum":100,"description":"Random jitter percentage (0-100) to avoid thundering herd"}}},"retry_if":{"$ref":"#/components/schemas/RetryIf"}}},"FlowNote":{"type":"object","description":"A sticky note attached to a flow for documentation and annotation","properties":{"id":{"type":"string","description":"Unique identifier for the note"},"text":{"type":"string","description":"Content of the note"},"position":{"type":"object","description":"Position of the note in the flow editor","properties":{"x":{"type":"number","description":"X coordinate"},"y":{"type":"number","description":"Y coordinate"}},"required":["x","y"]},"size":{"type":"object","description":"Size of the note in the flow editor","properties":{"width":{"type":"number","description":"Width in pixels"},"height":{"type":"number","description":"Height in pixels"}},"required":["width","height"]},"color":{"type":"string","description":"Color of the note (e.g., \\"yellow\\", \\"#ffff00\\")"},"type":{"type":"string","enum":["free","group"],"description":"Type of note - 'free' for standalone notes, 'group' for notes that group other nodes"},"locked":{"type":"boolean","default":false,"description":"Whether the note is locked and cannot be edited or moved"},"contained_node_ids":{"type":"array","items":{"type":"string"},"description":"For group notes, the IDs of nodes contained within this group"}},"required":["id","text","color","type"]},"RetryIf":{"type":"object","description":"Conditional retry based on error or result","properties":{"expr":{"type":"string","description":"JavaScript expression that returns true to retry. Has access to 'result' and 'error' variables"}},"required":["expr"]},"StopAfterIf":{"type":"object","description":"Early termination condition for a module","properties":{"skip_if_stopped":{"type":"boolean","description":"If true, following steps are skipped when this condition triggers"},"expr":{"type":"string","description":"JavaScript expression evaluated after the module runs. Can use 'result' (step's result) or 'flow_input'. Return true to stop"},"error_message":{"type":"string","description":"Custom error message shown when stopping"}},"required":["expr"]},"FlowModule":{"type":"object","description":"A single step in a flow. Can be a script, subflow, loop, or branch","properties":{"id":{"type":"string","description":"Unique identifier for this step. Used to reference results via 'results.step_id'. Must be a valid identifier (alphanumeric, underscore, hyphen)"},"value":{"$ref":"#/components/schemas/FlowModuleValue"},"stop_after_if":{"description":"Early termination condition evaluated after this step completes","$ref":"#/components/schemas/StopAfterIf"},"stop_after_all_iters_if":{"description":"For loops only - early termination condition evaluated after all iterations complete","$ref":"#/components/schemas/StopAfterIf"},"skip_if":{"type":"object","description":"Conditionally skip this step based on previous results or flow inputs","properties":{"expr":{"type":"string","description":"JavaScript expression that returns true to skip. Can use 'flow_input' or 'results.<step_id>'"}},"required":["expr"]},"sleep":{"description":"Delay before executing this step (in seconds or as expression)","$ref":"#/components/schemas/InputTransform"},"cache_ttl":{"type":"number","description":"Cache duration in seconds for this step's results"},"cache_ignore_s3_path":{"type":"boolean"},"timeout":{"description":"Maximum execution time in seconds (static value or expression)","$ref":"#/components/schemas/InputTransform"},"delete_after_use":{"type":"boolean","description":"If true, this step's result is deleted after use to save memory"},"summary":{"type":"string","description":"Short description of what this step does"},"mock":{"type":"object","description":"Mock configuration for testing without executing the actual step","properties":{"enabled":{"type":"boolean","description":"If true, return mock value instead of executing"},"return_value":{"description":"Value to return when mocked"}}},"suspend":{"type":"object","description":"Configuration for approval/resume steps that wait for user input","properties":{"required_events":{"type":"integer","description":"Number of approvals required before continuing"},"timeout":{"type":"integer","description":"Timeout in seconds before auto-continuing or canceling"},"resume_form":{"type":"object","description":"Form schema for collecting input when resuming","properties":{"schema":{"type":"object","description":"JSON Schema for the resume form"}}},"user_auth_required":{"type":"boolean","description":"If true, only authenticated users can approve"},"user_groups_required":{"description":"Expression or list of groups that can approve","$ref":"#/components/schemas/InputTransform"},"self_approval_disabled":{"type":"boolean","description":"If true, the user who started the flow cannot approve"},"hide_cancel":{"type":"boolean","description":"If true, hide the cancel button on the approval form"},"continue_on_disapprove_timeout":{"type":"boolean","description":"If true, continue flow on timeout instead of canceling"}}},"priority":{"type":"number","description":"Execution priority for this step (higher numbers run first)"},"continue_on_error":{"type":"boolean","description":"If true, flow continues even if this step fails"},"retry":{"description":"Retry configuration if this step fails","$ref":"#/components/schemas/Retry"}},"required":["value","id"]},"InputTransform":{"description":"Maps input parameters for a step. Can be a static value or a JavaScript expression that references previous results or flow inputs","oneOf":[{"$ref":"#/components/schemas/StaticTransform"},{"$ref":"#/components/schemas/JavascriptTransform"}],"discriminator":{"propertyName":"type","mapping":{"static":"#/components/schemas/StaticTransform","javascript":"#/components/schemas/JavascriptTransform"}}},"StaticTransform":{"type":"object","description":"Static value passed directly to the step. Use for hardcoded values or resource references like '$res:path/to/resource'","properties":{"value":{"description":"The static value. For resources, use format '$res:path/to/resource'"},"type":{"type":"string","enum":["static"]}},"required":["type"]},"JavascriptTransform":{"type":"object","description":"JavaScript expression evaluated at runtime. Can reference previous step results via 'results.step_id' or flow inputs via 'flow_input.property'. Inside loops, use 'flow_input.iter.value' for the current iteration value","properties":{"expr":{"type":"string","description":"JavaScript expression returning the value. Available variables - results (object with all previous step results), flow_input (flow inputs), flow_input.iter (in loops)"},"type":{"type":"string","enum":["javascript"]}},"required":["expr","type"]},"FlowModuleValue":{"description":"The actual implementation of a flow step. Can be a script (inline or referenced), subflow, loop, branch, or special module type","oneOf":[{"$ref":"#/components/schemas/RawScript"},{"$ref":"#/components/schemas/PathScript"},{"$ref":"#/components/schemas/PathFlow"},{"$ref":"#/components/schemas/ForloopFlow"},{"$ref":"#/components/schemas/WhileloopFlow"},{"$ref":"#/components/schemas/BranchOne"},{"$ref":"#/components/schemas/BranchAll"},{"$ref":"#/components/schemas/Identity"},{"$ref":"#/components/schemas/AiAgent"}],"discriminator":{"propertyName":"type","mapping":{"rawscript":"#/components/schemas/RawScript","script":"#/components/schemas/PathScript","flow":"#/components/schemas/PathFlow","forloopflow":"#/components/schemas/ForloopFlow","whileloopflow":"#/components/schemas/WhileloopFlow","branchone":"#/components/schemas/BranchOne","branchall":"#/components/schemas/BranchAll","identity":"#/components/schemas/Identity","aiagent":"#/components/schemas/AiAgent"}}},"RawScript":{"type":"object","description":"Inline script with code defined directly in the flow. Use 'bun' as default language if unspecified. The script receives arguments from input_transforms","properties":{"input_transforms":{"type":"object","description":"Map of parameter names to their values (static or JavaScript expressions). These become the script's input arguments","additionalProperties":{"$ref":"#/components/schemas/InputTransform"}},"content":{"type":"string","description":"The script source code. Should export a 'main' function"},"language":{"type":"string","description":"Programming language for this script","enum":["deno","bun","python3","go","bash","powershell","postgresql","mysql","bigquery","snowflake","mssql","oracledb","graphql","nativets","php"]},"path":{"type":"string","description":"Optional path for saving this script"},"lock":{"type":"string","description":"Lock file content for dependencies"},"type":{"type":"string","enum":["rawscript"]},"tag":{"type":"string","description":"Worker group tag for execution routing"},"concurrent_limit":{"type":"number","description":"Maximum concurrent executions of this script"},"concurrency_time_window_s":{"type":"number","description":"Time window for concurrent_limit"},"custom_concurrency_key":{"type":"string","description":"Custom key for grouping concurrent executions"},"is_trigger":{"type":"boolean","description":"If true, this script is a trigger that can start the flow"},"assets":{"type":"array","description":"External resources this script accesses (S3 objects, resources, etc.)","items":{"type":"object","required":["path","kind"],"properties":{"path":{"type":"string","description":"Path to the asset"},"kind":{"type":"string","description":"Type of asset","enum":["s3object","resource","ducklake","datatable"]},"access_type":{"type":"string","description":"Access level for this asset","enum":["r","w","rw"]},"alt_access_type":{"type":"string","description":"Alternative access level","enum":["r","w","rw"]}}}}},"required":["type","content","language","input_transforms"]},"PathScript":{"type":"object","description":"Reference to an existing script by path. Use this when calling a previously saved script instead of writing inline code","properties":{"input_transforms":{"type":"object","description":"Map of parameter names to their values (static or JavaScript expressions). These become the script's input arguments","additionalProperties":{"$ref":"#/components/schemas/InputTransform"}},"path":{"type":"string","description":"Path to the script in the workspace (e.g., 'f/scripts/send_email')"},"hash":{"type":"string","description":"Optional specific version hash of the script to use"},"type":{"type":"string","enum":["script"]},"tag_override":{"type":"string","description":"Override the script's default worker group tag"},"is_trigger":{"type":"boolean","description":"If true, this script is a trigger that can start the flow"}},"required":["type","path","input_transforms"]},"PathFlow":{"type":"object","description":"Reference to an existing flow by path. Use this to call another flow as a subflow","properties":{"input_transforms":{"type":"object","description":"Map of parameter names to their values (static or JavaScript expressions). These become the subflow's input arguments","additionalProperties":{"$ref":"#/components/schemas/InputTransform"}},"path":{"type":"string","description":"Path to the flow in the workspace (e.g., 'f/flows/process_user')"},"type":{"type":"string","enum":["flow"]}},"required":["type","path","input_transforms"]},"ForloopFlow":{"type":"object","description":"Executes nested modules in a loop over an iterator. Inside the loop, use 'flow_input.iter.value' to access the current iteration value, and 'flow_input.iter.index' for the index. Supports parallel execution for better performance on I/O-bound operations","properties":{"modules":{"type":"array","description":"Steps to execute for each iteration. These can reference the iteration value via 'flow_input.iter.value'","items":{"$ref":"#/components/schemas/FlowModule"}},"iterator":{"description":"JavaScript expression that returns an array to iterate over. Can reference 'results.step_id' or 'flow_input'","$ref":"#/components/schemas/InputTransform"},"skip_failures":{"type":"boolean","description":"If true, iteration failures don't stop the loop. Failed iterations return null"},"type":{"type":"string","enum":["forloopflow"]},"parallel":{"type":"boolean","description":"If true, iterations run concurrently (faster for I/O-bound operations). Use with parallelism to control concurrency"},"parallelism":{"description":"Maximum number of concurrent iterations when parallel=true. Limits resource usage. Can be static number or expression","$ref":"#/components/schemas/InputTransform"},"squash":{"type":"boolean"}},"required":["modules","iterator","skip_failures","type"]},"WhileloopFlow":{"type":"object","description":"Executes nested modules repeatedly while a condition is true. The loop checks the condition after each iteration. Use stop_after_if on modules to control loop termination","properties":{"modules":{"type":"array","description":"Steps to execute in each iteration. Use stop_after_if to control when the loop ends","items":{"$ref":"#/components/schemas/FlowModule"}},"skip_failures":{"type":"boolean","description":"If true, iteration failures don't stop the loop. Failed iterations return null"},"type":{"type":"string","enum":["whileloopflow"]},"parallel":{"type":"boolean","description":"If true, iterations run concurrently (use with caution in while loops)"},"parallelism":{"description":"Maximum number of concurrent iterations when parallel=true","$ref":"#/components/schemas/InputTransform"},"squash":{"type":"boolean"}},"required":["modules","skip_failures","type"]},"BranchOne":{"type":"object","description":"Conditional branching where only the first matching branch executes. Branches are evaluated in order, and the first one with a true expression runs. If no branches match, the default branch executes","properties":{"branches":{"type":"array","description":"Array of branches to evaluate in order. The first branch with expr evaluating to true executes","items":{"type":"object","properties":{"summary":{"type":"string","description":"Short description of this branch condition"},"expr":{"type":"string","description":"JavaScript expression that returns boolean. Can use 'results.step_id' or 'flow_input'. First true expr wins"},"modules":{"type":"array","description":"Steps to execute if this branch's expr is true","items":{"$ref":"#/components/schemas/FlowModule"}}},"required":["modules","expr"]}},"default":{"type":"array","description":"Steps to execute if no branch expressions match","items":{"$ref":"#/components/schemas/FlowModule"}},"type":{"type":"string","enum":["branchone"]}},"required":["branches","default","type"]},"BranchAll":{"type":"object","description":"Parallel branching where all branches execute simultaneously. Unlike BranchOne, all branches run regardless of conditions. Useful for executing independent tasks concurrently","properties":{"branches":{"type":"array","description":"Array of branches that all execute (either in parallel or sequentially)","items":{"type":"object","properties":{"summary":{"type":"string","description":"Short description of this branch's purpose"},"skip_failure":{"type":"boolean","description":"If true, failure in this branch doesn't fail the entire flow"},"modules":{"type":"array","description":"Steps to execute in this branch","items":{"$ref":"#/components/schemas/FlowModule"}}},"required":["modules"]}},"type":{"type":"string","enum":["branchall"]},"parallel":{"type":"boolean","description":"If true, all branches execute concurrently. If false, they execute sequentially"}},"required":["branches","type"]},"AgentTool":{"type":"object","description":"A tool available to an AI agent. Can be a flow module or an external MCP (Model Context Protocol) tool","properties":{"id":{"type":"string","description":"Unique identifier for this tool. Cannot contain spaces - use underscores instead (e.g., 'get_user_data' not 'get user data')"},"summary":{"type":"string","description":"Short description of what this tool does (shown to the AI)"},"value":{"$ref":"#/components/schemas/ToolValue"}},"required":["id","value"]},"ToolValue":{"description":"The implementation of a tool. Can be a flow module (script/flow) or an MCP tool reference","oneOf":[{"$ref":"#/components/schemas/FlowModuleTool"},{"$ref":"#/components/schemas/McpToolValue"}],"discriminator":{"propertyName":"tool_type","mapping":{"flowmodule":"#/components/schemas/FlowModuleTool","mcp":"#/components/schemas/McpToolValue"}}},"FlowModuleTool":{"description":"A tool implemented as a flow module (script, flow, etc.). The AI can call this like any other flow module","allOf":[{"type":"object","properties":{"tool_type":{"type":"string","enum":["flowmodule"]}},"required":["tool_type"]},{"$ref":"#/components/schemas/FlowModuleValue"}]},"McpToolValue":{"type":"object","description":"Reference to an external MCP (Model Context Protocol) tool. The AI can call tools from MCP servers","properties":{"tool_type":{"type":"string","enum":["mcp"]},"resource_path":{"type":"string","description":"Path to the MCP resource/server configuration"},"include_tools":{"type":"array","description":"Whitelist of specific tools to include from this MCP server","items":{"type":"string"}},"exclude_tools":{"type":"array","description":"Blacklist of tools to exclude from this MCP server","items":{"type":"string"}}},"required":["tool_type","resource_path"]},"AiAgent":{"type":"object","description":"AI agent step that can use tools to accomplish tasks. The agent receives inputs and can call any of its configured tools to complete the task","properties":{"input_transforms":{"type":"object","description":"Input parameters for the AI agent mapped to their values","properties":{"provider":{"$ref":"#/components/schemas/InputTransform"},"output_type":{"$ref":"#/components/schemas/InputTransform"},"user_message":{"$ref":"#/components/schemas/InputTransform"},"system_prompt":{"$ref":"#/components/schemas/InputTransform"},"streaming":{"$ref":"#/components/schemas/InputTransform"},"messages_context_length":{"$ref":"#/components/schemas/InputTransform"},"output_schema":{"$ref":"#/components/schemas/InputTransform"},"user_images":{"$ref":"#/components/schemas/InputTransform"},"max_completion_tokens":{"$ref":"#/components/schemas/InputTransform"},"temperature":{"$ref":"#/components/schemas/InputTransform"}},"required":["provider","user_message","output_type"]},"tools":{"type":"array","description":"Array of tools the agent can use. The agent decides which tools to call based on the task","items":{"$ref":"#/components/schemas/AgentTool"}},"type":{"type":"string","enum":["aiagent"]},"parallel":{"type":"boolean","description":"If true, the agent can execute multiple tool calls in parallel"}},"required":["tools","type","input_transforms"]},"Identity":{"type":"object","description":"Pass-through module that returns its input unchanged. Useful for flow structure or as a placeholder","properties":{"type":{"type":"string","enum":["identity"]},"flow":{"type":"boolean","description":"If true, marks this as a flow identity (special handling)"}},"required":["type"]},"FlowStatus":{"type":"object","properties":{"step":{"type":"integer"},"modules":{"type":"array","items":{"$ref":"#/components/schemas/FlowStatusModule"}},"user_states":{"additionalProperties":true},"preprocessor_module":{"allOf":[{"$ref":"#/components/schemas/FlowStatusModule"}]},"failure_module":{"allOf":[{"$ref":"#/components/schemas/FlowStatusModule"},{"type":"object","properties":{"parent_module":{"type":"string"}}}]},"retry":{"type":"object","properties":{"fail_count":{"type":"integer"},"failed_jobs":{"type":"array","items":{"type":"string","format":"uuid"}}}}},"required":["step","modules","failure_module"]},"FlowStatusModule":{"type":"object","properties":{"type":{"type":"string","enum":["WaitingForPriorSteps","WaitingForEvents","WaitingForExecutor","InProgress","Success","Failure"]},"id":{"type":"string"},"job":{"type":"string","format":"uuid"},"count":{"type":"integer"},"progress":{"type":"integer"},"iterator":{"type":"object","properties":{"index":{"type":"integer"},"itered":{"type":"array","items":{}},"args":{}}},"flow_jobs":{"type":"array","items":{"type":"string"}},"flow_jobs_success":{"type":"array","items":{"type":"boolean"}},"flow_jobs_duration":{"type":"object","properties":{"started_at":{"type":"array","items":{"type":"string"}},"duration_ms":{"type":"array","items":{"type":"integer"}}}},"branch_chosen":{"type":"object","properties":{"type":{"type":"string","enum":["branch","default"]},"branch":{"type":"integer"}},"required":["type"]},"branchall":{"type":"object","properties":{"branch":{"type":"integer"},"len":{"type":"integer"}},"required":["branch","len"]},"approvers":{"type":"array","items":{"type":"object","properties":{"resume_id":{"type":"integer"},"approver":{"type":"string"}},"required":["resume_id","approver"]}},"failed_retries":{"type":"array","items":{"type":"string","format":"uuid"}},"skipped":{"type":"boolean"},"agent_actions":{"type":"array","items":{"type":"object","oneOf":[{"type":"object","properties":{"job_id":{"type":"string","format":"uuid"},"function_name":{"type":"string"},"type":{"type":"string","enum":["tool_call"]},"module_id":{"type":"string"}},"required":["job_id","function_name","type","module_id"]},{"type":"object","properties":{"call_id":{"type":"string","format":"uuid"},"function_name":{"type":"string"},"resource_path":{"type":"string"},"type":{"type":"string","enum":["mcp_tool_call"]},"arguments":{"type":"object"}},"required":["call_id","function_name","resource_path","type"]},{"type":"object","properties":{"type":{"type":"string","enum":["message"]}},"required":["content","type"]}]}},"agent_actions_success":{"type":"array","items":{"type":"boolean"}}},"required":["type"]}}`;

export const RESOURCE_TYPES = `# Resource Types

On Windmill, credentials and configuration are stored in resources. Resource types define the format of the resource.

## Using Resources in Scripts

### TypeScript (Bun/Deno)

Use the \`RT\` namespace for resource types as parameters:

\`\`\`typescript
export async function main(stripe: RT.Stripe, db: RT.Postgresql) {
  // stripe and db contain the resource values
}
\`\`\`

### Python

Redefine the resource type as a TypedDict (lowercase name):

\`\`\`python
from typing import TypedDict

class postgresql(TypedDict):
    host: str
    port: int
    user: str
    password: str
    dbname: str

def main(db: postgresql):
    pass
\`\`\`

### PHP

Define the resource type as a class:

\`\`\`php
<?php

if (!class_exists('Postgresql')) {
    class Postgresql {
        public string $host;
        public int $port;
        public string $user;
        public string $password;
        public string $dbname;
    }
}

function main(Postgresql $db) {
    // ...
}
\`\`\`

## Using Resources in Flows

### As Flow Input

In the flow schema, set the property type to \`"object"\` with format \`"resource-{type}"\`:

\`\`\`json
{
  "type": "object",
  "properties": {
    "database": {
      "type": "object",
      "format": "resource-postgresql",
      "description": "Database connection"
    }
  }
}
\`\`\`

### As Step Input (Static Reference)

Reference a specific resource using \`$res:\` prefix:

\`\`\`json
{
  "database": {
    "type": "static",
    "value": "$res:f/folder/my_database"
  }
}
\`\`\`

## Common Resource Types

- \`postgresql\` - PostgreSQL database connection
- \`mysql\` - MySQL database connection
- \`mongodb\` - MongoDB connection
- \`s3\` - S3-compatible storage
- \`slack\` - Slack API credentials
- \`stripe\` - Stripe API key
- \`openai\` - OpenAI API key
- \`smtp\` - Email server configuration
- \`http\` - Generic HTTP authentication
`;

export const S3_OBJECTS = `# S3 Object Operations

Windmill provides built-in support for S3-compatible storage operations.

## S3Object Type

The S3Object type represents a file in S3 storage:

\`\`\`typescript
type S3Object = {
  s3: string;  // Path within the bucket
}
\`\`\`

## TypeScript Operations

\`\`\`typescript
import * as wmill from 'windmill-client'

// Load file content from S3
const content: Uint8Array = await wmill.loadS3File(s3object)

// Load file as stream
const blob: Blob = await wmill.loadS3FileStream(s3object)

// Write file to S3
const result: S3Object = await wmill.writeS3File(
  s3object,      // Target path (or undefined to auto-generate)
  fileContent,   // string or Blob
  s3ResourcePath // Optional: specific S3 resource to use
)
\`\`\`

## Python Operations

\`\`\`python
import wmill

# Load file content from S3
content: bytes = wmill.load_s3_file(s3object)

# Load file as stream reader
reader: BufferedReader = wmill.load_s3_file_reader(s3object)

# Write file to S3
result: S3Object = wmill.write_s3_file(
    s3object,           # Target path (or None to auto-generate)
    file_content,       # bytes or BufferedReader
    s3_resource_path,   # Optional: specific S3 resource
    content_type,       # Optional: MIME type
    content_disposition # Optional: Content-Disposition header
)
\`\`\`

## DuckDB S3 Operations

Read files directly from S3 in DuckDB queries:

\`\`\`sql
-- Read CSV from default S3 storage
SELECT * FROM read_csv('s3:///path/to/file.csv');

-- Read from named storage
SELECT * FROM read_csv('s3://storage_name/path/to/file.csv');

-- Read Parquet files
SELECT * FROM read_parquet('s3:///data/*.parquet');

-- Read JSON files
SELECT * FROM read_json('s3:///path/to/file.json');
\`\`\`

## Flow Input Schema

To accept an S3 object as flow input:

\`\`\`json
{
  "type": "object",
  "properties": {
    "file": {
      "type": "object",
      "format": "resource-s3_object",
      "description": "File to process"
    }
  }
}
\`\`\`
`;

export const CLI_COMMANDS = `# Windmill CLI Commands

The Windmill CLI (\`wmill\`) provides commands for managing scripts, flows, apps, and other resources.

## Global Options

- \`--workspace <workspace>\` - Specify target workspace (overrides default)
- \`--token <token>\` - Specify API token (overrides stored token)
- \`--base-url <url>\` - Specify API base URL
- \`--debug\` / \`--verbose\` - Show debug logs
- \`--show-diffs\` - Show diff information when syncing

## Core Commands

### Project Setup

- \`wmill init\` - Bootstrap a windmill project with wmill.yaml
  - \`--use-default\` - Use default settings without checking backend
  - \`--use-backend\` - Use backend git-sync settings if available
  - \`--bind-profile\` - Bind workspace profile to current Git branch

### Workspace Management

- \`wmill workspace\` - Manage workspaces
  - \`wmill workspace add\` - Add a new workspace
  - \`wmill workspace switch\` - Switch active workspace
  - \`wmill workspace list\` - List configured workspaces

### Sync Operations

- \`wmill sync pull\` - Pull remote changes to local
  - \`--raw\` - Pull without converting to local format
  - \`--yes\` - Skip confirmation prompts
  - \`--include-schedules\` - Include schedules in sync
  - \`--include-triggers\` - Include triggers in sync

- \`wmill sync push\` - Push local changes to remote
  - \`--dry-run\` - Preview changes without applying
  - \`--yes\` - Skip confirmation prompts
  - \`--fail-conflicts\` - Fail on conflicts instead of prompting

### Scripts

- \`wmill script\` - Manage scripts
  - \`wmill script push <path>\` - Push a script to remote
  - \`wmill script generate-metadata\` - Generate script metadata from code
    - Analyzes script code and creates/updates the \`.script.yaml\` metadata file
    - Infers parameter types, descriptions, and schema from code annotations

### Flows

- \`wmill flow\` - Manage flows
  - \`wmill flow push <path>\` - Push a flow to remote
  - \`wmill flow generate-locks\` - Generate lock files for flow dependencies
    - \`--yes\` - Skip confirmation prompts

### Apps

- \`wmill app\` - Manage apps
  - \`wmill app push <path>\` - Push an app to remote
  - \`wmill app generate-locks\` - Generate lock files for app dependencies

### Resources

- \`wmill resource\` - Manage resources
  - \`wmill resource push\` - Push resources to remote
  - \`wmill resource pull\` - Pull resources from remote

- \`wmill resource-type\` - Manage resource types
  - \`wmill resource-type push\` - Push resource types
  - \`wmill resource-type pull\` - Pull resource types

### Variables

- \`wmill variable\` - Manage variables
  - \`wmill variable push\` - Push variables to remote
  - \`wmill variable pull\` - Pull variables from remote

### Hub

- \`wmill hub\` - Interact with Windmill Hub
  - \`wmill hub pull <path>\` - Pull a script/flow from the hub

### Development

- \`wmill dev\` - Start development mode with file watching

### Other Commands

- \`wmill folder\` - Manage folders
- \`wmill schedule\` - Manage schedules
- \`wmill trigger\` - Manage triggers
- \`wmill user\` - Manage users
- \`wmill jobs\` - Manage jobs
- \`wmill workers\` - View worker status
- \`wmill queues\` - View queue status
- \`wmill dependencies\` - Manage dependencies
- \`wmill instance\` - Instance-level operations
- \`wmill worker-groups\` - Manage worker groups
- \`wmill gitsync-settings\` - Manage git-sync settings
- \`wmill upgrade\` - Upgrade CLI to latest version
- \`wmill completions\` - Generate shell completions

## Workflow Instructions

### After Writing a Script

After creating or modifying a script, run:
\`\`\`bash
wmill script generate-metadata <path>
\`\`\`

This will analyze your script code and generate/update the \`.script.yaml\` metadata file with inferred types and schema.

### After Writing a Flow

After creating or modifying a flow, run:
\`\`\`bash
wmill flow generate-locks --yes
\`\`\`

This generates lock files for all flow dependencies.

### Syncing Changes

To push all local changes to the remote workspace:
\`\`\`bash
wmill sync push
\`\`\`

To pull remote changes to local:
\`\`\`bash
wmill sync pull
\`\`\`
`;

export const LANG_PYTHON3 = `# Python

## Structure

The script must contain at least one function called \`main\`:

\`\`\`python
def main(param1: str, param2: int):
    # Your code here
    return {"result": param1, "count": param2}
\`\`\`

Do not call the main function. Libraries are installed automatically.

## Resource Types

On Windmill, credentials and configuration are stored in resources and passed as parameters to main.

You need to **redefine** the type of the resources that are needed before the main function as TypedDict:

\`\`\`python
from typing import TypedDict

class postgresql(TypedDict):
    host: str
    port: int
    user: str
    password: str
    dbname: str

def main(db: postgresql):
    # db contains the database connection details
    pass
\`\`\`

**Important rules:**
- The resource type name must be **IN LOWERCASE**
- Only include resource types if they are actually needed
- If an import conflicts with a resource type name, **rename the imported object, not the type name**
- Make sure to import TypedDict from typing **if you're using it**

## Imports

Libraries are installed automatically. Do not show installation instructions.

\`\`\`python
import requests
import pandas as pd
from datetime import datetime
\`\`\`

If an import name conflicts with a resource type:
\`\`\`python
# Wrong - don't rename the type
import stripe as stripe_lib
class stripe_type(TypedDict): ...

# Correct - rename the import
import stripe as stripe_sdk
class stripe(TypedDict):
    api_key: str
\`\`\`

## Windmill Client

Import the windmill client for platform interactions:

\`\`\`python
import wmill
\`\`\`

See the SDK documentation for available methods.

## Preprocessor Scripts

For preprocessor scripts, the function should be named \`preprocessor\` and receives an \`event\` parameter:

\`\`\`python
from typing import TypedDict, Literal, Any

class Event(TypedDict):
    kind: Literal["webhook", "http", "websocket", "kafka", "email", "nats", "postgres", "sqs", "mqtt", "gcp"]
    body: Any
    headers: dict[str, str]
    query: dict[str, str]

def preprocessor(event: Event):
    # Transform the event into flow input parameters
    return {
        "param1": event["body"]["field1"],
        "param2": event["query"]["id"]
    }
\`\`\`
`;

export const LANG_BUN = `# TypeScript (Bun)

Bun runtime with full npm ecosystem and fastest execution.

## Structure

Export a single **async** function called \`main\`:

\`\`\`typescript
export async function main(param1: string, param2: number) {
  // Your code here
  return { result: param1, count: param2 };
}
\`\`\`

Do not call the main function. Libraries are installed automatically.

## Resource Types

On Windmill, credentials and configuration are stored in resources and passed as parameters to main.

Use the \`RT\` namespace for resource types:

\`\`\`typescript
export async function main(stripe: RT.Stripe) {
  // stripe contains API key and config from the resource
}
\`\`\`

Only use resource types if you need them to satisfy the instructions. Always use the RT namespace.

## Imports

\`\`\`typescript
import Stripe from 'stripe'
import { someFunction } from 'some-package'
\`\`\`

## Windmill Client

Import the windmill client for platform interactions:

\`\`\`typescript
import * as wmill from 'windmill-client'
\`\`\`

See the SDK documentation for available methods.

## Preprocessor Scripts

For preprocessor scripts, the function should be named \`preprocessor\` and receives an \`event\` parameter:

\`\`\`typescript
type Event = {
  kind:
    | "webhook"
    | "http"
    | "websocket"
    | "kafka"
    | "email"
    | "nats"
    | "postgres"
    | "sqs"
    | "mqtt"
    | "gcp";
  body: any;
  headers: Record<string, string>;
  query: Record<string, string>;
};

export async function preprocessor(event: Event) {
  return {
    param1: event.body.field1,
    param2: event.query.id
  };
}
\`\`\`
`;

export const LANG_MYSQL = `# MySQL

Arguments use \`?\` placeholders.

Name the parameters by adding comments before the statement:

\`\`\`sql
-- ? name1 (text)
-- ? name2 (int) = 0
SELECT * FROM users WHERE name = ? AND age > ?;
\`\`\`
`;

export const LANG_POWERSHELL = `# PowerShell

## Structure

Arguments are obtained by calling the \`param\` function on the first line:

\`\`\`powershell
param($Name, $Count = 0, [int]$Age)

# Your code here
Write-Output "Processing $Name, count: $Count, age: $Age"

# Return object
@{
    name = $Name
    count = $Count
    age = $Age
}
\`\`\`

## Parameter Types

You can specify types for parameters:

\`\`\`powershell
param(
    [string]$Name,
    [int]$Count = 0,
    [bool]$Enabled = $true,
    [array]$Items
)

@{
    name = $Name
    count = $Count
    enabled = $Enabled
    items = $Items
}
\`\`\`

## Return Values

Return values by outputting them at the end of the script:

\`\`\`powershell
param($Input)

$result = @{
    processed = $true
    data = $Input
    timestamp = Get-Date -Format "o"
}

$result
\`\`\`
`;

export const LANG_SNOWFLAKE = `# Snowflake

Arguments use \`?\` placeholders.

Name the parameters by adding comments before the statement:

\`\`\`sql
-- ? name1 (text)
-- ? name2 (number) = 0
SELECT * FROM users WHERE name = ? AND age > ?;
\`\`\`
`;

export const LANG_GO = `# Go

## Structure

The file package must be \`inner\` and export a function called \`main\`:

\`\`\`go
package inner

func main(param1 string, param2 int) (map[string]interface{}, error) {
    return map[string]interface{}{
        "result": param1,
        "count":  param2,
    }, nil
}
\`\`\`

**Important:**
- Package must be \`inner\`
- Return type must be \`({return_type}, error)\`
- Function name is \`main\` (lowercase)

## Return Types

The return type can be any Go type that can be serialized to JSON:

\`\`\`go
package inner

type Result struct {
    Name  string \`json:"name"\`
    Count int    \`json:"count"\`
}

func main(name string, count int) (Result, error) {
    return Result{
        Name:  name,
        Count: count,
    }, nil
}
\`\`\`

## Error Handling

Return errors as the second return value:

\`\`\`go
package inner

import "errors"

func main(value int) (string, error) {
    if value < 0 {
        return "", errors.New("value must be positive")
    }
    return "success", nil
}
\`\`\`
`;

export const LANG_DENO = `# TypeScript (Deno)

Deno runtime with npm support via \`npm:\` prefix and native Deno libraries.

## Structure

Export a single **async** function called \`main\`:

\`\`\`typescript
export async function main(param1: string, param2: number) {
  // Your code here
  return { result: param1, count: param2 };
}
\`\`\`

Do not call the main function. Libraries are installed automatically.

## Resource Types

On Windmill, credentials and configuration are stored in resources and passed as parameters to main.

Use the \`RT\` namespace for resource types:

\`\`\`typescript
export async function main(stripe: RT.Stripe) {
  // stripe contains API key and config from the resource
}
\`\`\`

Only use resource types if you need them to satisfy the instructions. Always use the RT namespace.

## Imports

\`\`\`typescript
// npm packages use npm: prefix
import Stripe from 'npm:stripe'
import { someFunction } from 'npm:some-package'

// Deno standard library
import { serve } from 'https://deno.land/std/http/server.ts'
\`\`\`

## Windmill Client

Import the windmill client for platform interactions:

\`\`\`typescript
import * as wmill from 'windmill-client'
\`\`\`

See the SDK documentation for available methods.

## Preprocessor Scripts

For preprocessor scripts, the function should be named \`preprocessor\` and receives an \`event\` parameter:

\`\`\`typescript
type Event = {
  kind:
    | "webhook"
    | "http"
    | "websocket"
    | "kafka"
    | "email"
    | "nats"
    | "postgres"
    | "sqs"
    | "mqtt"
    | "gcp";
  body: any;
  headers: Record<string, string>;
  query: Record<string, string>;
};

export async function preprocessor(event: Event) {
  return {
    param1: event.body.field1,
    param2: event.query.id
  };
}
\`\`\`
`;

export const LANG_BASH = `# Bash

## Structure

Do not include \`#!/bin/bash\`. Arguments are obtained as positional parameters:

\`\`\`bash
# Get arguments
var1="$1"
var2="$2"

echo "Processing $var1 and $var2"

# Return JSON by echoing to stdout
echo "{\\"result\\": \\"$var1\\", \\"count\\": $var2}"
\`\`\`

**Important:**
- Do not include shebang (\`#!/bin/bash\`)
- Arguments are always strings
- Access with \`$1\`, \`$2\`, etc.

## Output

The script output is captured as the result. For structured data, output valid JSON:

\`\`\`bash
name="$1"
count="$2"

# Output JSON result
cat << EOF
{
  "name": "$name",
  "count": $count,
  "timestamp": "$(date -Iseconds)"
}
EOF
\`\`\`

## Environment Variables

Environment variables set in Windmill are available:

\`\`\`bash
# Access environment variable
echo "Workspace: $WM_WORKSPACE"
echo "Job ID: $WM_JOB_ID"
\`\`\`
`;

export const LANG_BUNNATIVE = `# TypeScript (Bun Native)

Native TypeScript execution with fetch only - no external imports allowed.

## Structure

Export a single **async** function called \`main\`:

\`\`\`typescript
export async function main(param1: string, param2: number) {
  // Your code here
  return { result: param1, count: param2 };
}
\`\`\`

Do not call the main function.

## Resource Types

On Windmill, credentials and configuration are stored in resources and passed as parameters to main.

Use the \`RT\` namespace for resource types:

\`\`\`typescript
export async function main(stripe: RT.Stripe) {
  // stripe contains API key and config from the resource
}
\`\`\`

Only use resource types if you need them to satisfy the instructions. Always use the RT namespace.

## Imports

**No imports allowed.** Use the globally available \`fetch\` function:

\`\`\`typescript
export async function main(url: string) {
  const response = await fetch(url);
  return await response.json();
}
\`\`\`

## Windmill Client

The windmill client is not available in native TypeScript mode. Use fetch to call APIs directly.

## Preprocessor Scripts

For preprocessor scripts, the function should be named \`preprocessor\` and receives an \`event\` parameter:

\`\`\`typescript
type Event = {
  kind:
    | "webhook"
    | "http"
    | "websocket"
    | "kafka"
    | "email"
    | "nats"
    | "postgres"
    | "sqs"
    | "mqtt"
    | "gcp";
  body: any;
  headers: Record<string, string>;
  query: Record<string, string>;
};

export async function preprocessor(event: Event) {
  return {
    param1: event.body.field1,
    param2: event.query.id
  };
}
\`\`\`
`;

export const LANG_DUCKDB = `# DuckDB

Arguments are defined with comments and used with \`$name\` syntax:

\`\`\`sql
-- $name (text) = default
-- $age (integer)
SELECT * FROM users WHERE name = $name AND age > $age;
\`\`\`

## Ducklake Integration

Attach Ducklake for data lake operations:

\`\`\`sql
-- Main ducklake
ATTACH 'ducklake' AS dl;

-- Named ducklake
ATTACH 'ducklake://my_lake' AS dl;

-- Then query
SELECT * FROM dl.schema.table;
\`\`\`

## External Database Connections

Connect to external databases using resources:

\`\`\`sql
ATTACH '$res:path/to/resource' AS db (TYPE postgres);
SELECT * FROM db.schema.table;
\`\`\`

## S3 File Operations

Read files from S3 storage:

\`\`\`sql
-- Default storage
SELECT * FROM read_csv('s3:///path/to/file.csv');

-- Named storage
SELECT * FROM read_csv('s3://storage_name/path/to/file.csv');

-- Parquet files
SELECT * FROM read_parquet('s3:///path/to/file.parquet');

-- JSON files
SELECT * FROM read_json('s3:///path/to/file.json');
\`\`\`
`;

export const LANG_NATIVETS = `# TypeScript (Native)

Native TypeScript execution with fetch only - no external imports allowed.

## Structure

Export a single **async** function called \`main\`:

\`\`\`typescript
export async function main(param1: string, param2: number) {
  // Your code here
  return { result: param1, count: param2 };
}
\`\`\`

Do not call the main function.

## Resource Types

On Windmill, credentials and configuration are stored in resources and passed as parameters to main.

Use the \`RT\` namespace for resource types:

\`\`\`typescript
export async function main(stripe: RT.Stripe) {
  // stripe contains API key and config from the resource
}
\`\`\`

Only use resource types if you need them to satisfy the instructions. Always use the RT namespace.

## Imports

**No imports allowed.** Use the globally available \`fetch\` function:

\`\`\`typescript
export async function main(url: string) {
  const response = await fetch(url);
  return await response.json();
}
\`\`\`

## Windmill Client

The windmill client is not available in native TypeScript mode. Use fetch to call APIs directly.

## Preprocessor Scripts

For preprocessor scripts, the function should be named \`preprocessor\` and receives an \`event\` parameter:

\`\`\`typescript
type Event = {
  kind:
    | "webhook"
    | "http"
    | "websocket"
    | "kafka"
    | "email"
    | "nats"
    | "postgres"
    | "sqs"
    | "mqtt"
    | "gcp";
  body: any;
  headers: Record<string, string>;
  query: Record<string, string>;
};

export async function preprocessor(event: Event) {
  return {
    param1: event.body.field1,
    param2: event.query.id
  };
}
\`\`\`
`;

export const LANG_BIGQUERY = `# BigQuery

Arguments use \`@name\` syntax.

Name the parameters by adding comments before the statement:

\`\`\`sql
-- @name1 (string)
-- @name2 (int64) = 0
SELECT * FROM users WHERE name = @name1 AND age > @name2;
\`\`\`
`;

export const LANG_RUST = `# Rust

## Structure

The script must contain a function called \`main\` with proper return type:

\`\`\`rust
use anyhow::anyhow;
use serde::Serialize;

#[derive(Serialize, Debug)]
struct ReturnType {
    result: String,
    count: i32,
}

fn main(param1: String, param2: i32) -> anyhow::Result<ReturnType> {
    Ok(ReturnType {
        result: param1,
        count: param2,
    })
}
\`\`\`

**Important:**
- Arguments should be owned types
- Return type must be serializable (\`#[derive(Serialize)]\`)
- Return type is \`anyhow::Result<T>\`

## Dependencies

Packages must be specified with a partial cargo.toml at the beginning of the script:

\`\`\`rust
//! \`\`\`cargo
//! [dependencies]
//! anyhow = "1.0.86"
//! reqwest = { version = "0.11", features = ["json"] }
//! tokio = { version = "1", features = ["full"] }
//! \`\`\`

use anyhow::anyhow;
// ... rest of the code
\`\`\`

**Note:** Serde is already included, no need to add it again.

## Async Functions

If you need to handle async functions (e.g., using tokio), keep the main function sync and create the runtime inside:

\`\`\`rust
//! \`\`\`cargo
//! [dependencies]
//! anyhow = "1.0.86"
//! tokio = { version = "1", features = ["full"] }
//! reqwest = { version = "0.11", features = ["json"] }
//! \`\`\`

use anyhow::anyhow;
use serde::Serialize;

#[derive(Serialize, Debug)]
struct Response {
    data: String,
}

fn main(url: String) -> anyhow::Result<Response> {
    let rt = tokio::runtime::Runtime::new()?;
    rt.block_on(async {
        let resp = reqwest::get(&url).await?.text().await?;
        Ok(Response { data: resp })
    })
}
\`\`\`
`;

export const LANG_PHP = `# PHP

## Structure

The script must start with \`<?php\` and contain at least one function called \`main\`:

\`\`\`php
<?php

function main(string $param1, int $param2) {
    return ["result" => $param1, "count" => $param2];
}
\`\`\`

## Resource Types

On Windmill, credentials and configuration are stored in resources and passed as parameters to main.

You need to **redefine** the type of the resources that are needed before the main function. Always check if the class already exists using \`class_exists\`:

\`\`\`php
<?php

if (!class_exists('Postgresql')) {
    class Postgresql {
        public string $host;
        public int $port;
        public string $user;
        public string $password;
        public string $dbname;
    }
}

function main(Postgresql $db) {
    // $db contains the database connection details
}
\`\`\`

The resource type name has to be exactly as specified.

## Library Dependencies

Specify library dependencies as comments before the main function:

\`\`\`php
<?php

// require:
// guzzlehttp/guzzle
// stripe/stripe-php@^10.0

function main() {
    // Libraries are available
}
\`\`\`

One dependency per line. No need to require autoload, it is already done.
`;

export const LANG_MSSQL = `# Microsoft SQL Server (MSSQL)

Arguments use \`@P1\`, \`@P2\`, etc.

Name the parameters by adding comments before the statement:

\`\`\`sql
-- @P1 name1 (varchar)
-- @P2 name2 (int) = 0
SELECT * FROM users WHERE name = @P1 AND age > @P2;
\`\`\`
`;

export const LANG_POSTGRESQL = `# PostgreSQL

Arguments are obtained directly in the statement with \`$1::{type}\`, \`$2::{type}\`, etc.

Name the parameters by adding comments at the beginning of the script (without specifying the type):

\`\`\`sql
-- $1 name1
-- $2 name2 = default_value
SELECT * FROM users WHERE name = $1::TEXT AND age > $2::INT;
\`\`\`
`;

export const LANG_GRAPHQL = `# GraphQL

## Structure

Write GraphQL queries or mutations. Arguments can be added as query parameters:

\`\`\`graphql
query GetUser($id: ID!) {
  user(id: $id) {
    id
    name
    email
  }
}
\`\`\`

## Variables

Variables are passed as script arguments and automatically bound to the query:

\`\`\`graphql
query SearchProducts($query: String!, $limit: Int = 10) {
  products(search: $query, first: $limit) {
    edges {
      node {
        id
        name
        price
      }
    }
  }
}
\`\`\`

## Mutations

\`\`\`graphql
mutation CreateUser($input: CreateUserInput!) {
  createUser(input: $input) {
    id
    name
    createdAt
  }
}
\`\`\`
`;

export const LANG_CSHARP = `# C#

The script must contain a public static \`Main\` method inside a class:

\`\`\`csharp
public class Script
{
    public static object Main(string name, int count)
    {
        return new { Name = name, Count = count };
    }
}
\`\`\`

**Important:**
- Class name is irrelevant
- Method must be \`public static\`
- Return type can be \`object\` or specific type

## NuGet Packages

Add packages using the \`#r\` directive at the top:

\`\`\`csharp
#r "nuget: Newtonsoft.Json, 13.0.3"
#r "nuget: RestSharp, 110.2.0"

using Newtonsoft.Json;
using RestSharp;

public class Script
{
    public static object Main(string url)
    {
        var client = new RestClient(url);
        var request = new RestRequest();
        var response = client.Get(request);
        return JsonConvert.DeserializeObject(response.Content);
    }
}
\`\`\`
`;

export const LANG_JAVA = `# Java

The script must contain a Main public class with a \`public static main()\` method:

\`\`\`java
public class Main {
    public static Object main(String name, int count) {
        java.util.Map<String, Object> result = new java.util.HashMap<>();
        result.put("name", name);
        result.put("count", count);
        return result;
    }
}
\`\`\`

**Important:**
- Class must be named \`Main\`
- Method must be \`public static Object main(...)\`
- Return type is \`Object\` or \`void\`

## Maven Dependencies

Add dependencies using comments at the top:

\`\`\`java
//requirements:
//com.google.code.gson:gson:2.10.1
//org.apache.httpcomponents:httpclient:4.5.14

import com.google.gson.Gson;

public class Main {
    public static Object main(String input) {
        Gson gson = new Gson();
        return gson.fromJson(input, Object.class);
    }
}
\`\`\`
`;

