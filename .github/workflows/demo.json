{
  "instructions": "Demo: AI Model Token Limits Configuration\n\nüéØ **Feature Overview**\nThis demo showcases the new Model Token Limits feature that allows workspace administrators to configure maximum token limits for individual AI models. This provides fine-grained control over AI usage across the workspace.\n\nüìã **Step-by-Step Demo Instructions**\n\n**Step 1: Navigate to Workspace Settings**\n- Go to the preview URL\n- Navigate to Workspace Settings (gear icon in the sidebar)\n- Click on the \"AI Settings\" tab\n\n**Step 2: Configure AI Providers (if not already done)**\n- Enable at least one AI provider by toggling it on (e.g., OpenAI, Anthropic, or Mistral)\n- Configure the resource path with valid credentials\n- Select one or more models from the \"Enabled models\" dropdown\n- If you don't have real credentials, you can still see the UI structure\n\n**Step 3: Explore Model Token Limits**\n- Scroll down to see the new \"Model Output Limits\" section\n- Notice the description: \"Configure maximum token limits for each model. These limits apply to all AI chat interactions in the workspace.\"\n- You'll see each configured AI provider listed as collapsible sections\n\n**Step 4: Configure Token Limits**\n- Click on any provider name (e.g., \"OpenAI\") to expand it\n- Each model will be displayed with:\n  - Model name on the left\n  - Current token limit input field (number input)\n  - \"tokens\" label\n- Try changing a token limit value in the input field\n- Notice how a \"Modified\" badge appears next to the provider name\n\n**Step 5: Test Validation and Reset Features**\n- Try setting an extremely high value (over 2,000,000) to see validation\n- Try setting a negative value to see validation errors\n- For any modified model, notice the \"Default: X tokens\" text appears\n- Click the \"Reset\" link to restore a model to its default limit\n- Watch the \"Modified\" badge disappear when all models return to defaults\n\n**Step 6: Save Configuration**\n- Click the \"Save\" button to persist your token limit settings\n- The settings will be saved to the workspace configuration\n\n**üîç Key Features to Highlight**\n- **Collapsible Interface**: Each provider can be expanded/collapsed for better organization\n- **Modified Indicators**: Clear visual feedback when settings differ from defaults\n- **Input Validation**: Prevents invalid token limits (must be 1-2,000,000)\n- **Default Reset**: Easy way to restore default values\n- **Real-time Updates**: Changes are reflected immediately in the UI\n- **Per-Model Granularity**: Each model can have its own unique token limit\n\n**üí° Business Value**\n- **Cost Control**: Administrators can limit AI usage to prevent unexpected costs\n- **Performance Optimization**: Shorter responses can improve response times\n- **Policy Compliance**: Organizations can enforce token usage policies\n- **Flexible Configuration**: Different models can have different appropriate limits\n\n**üé® UI/UX Highlights**\n- Clean, intuitive interface with clear visual hierarchy\n- Smooth expand/collapse animations\n- Consistent with Windmill's design system\n- Helpful tooltips and descriptions\n- Responsive input validation with immediate feedback",
  "url": "https://fg-max-tokens.windmill.pages.dev/"
}