const __vite__mapDeps=(i,m=__vite__mapDeps,d=(m.f||(m.f=["assets/main-DHcIJauR.js","assets/index-BfSJrKL5.js","assets/index-DTuONjBt.css","assets/main-QaSRAa8f.js"])))=>i.map(i=>d[i]);
import{a9 as ce,aa as ge,ab as ue,ac as S,ad as Q,ae as W,af as B,D as C,s as de,ag as le,ah as U,U as he,ai as X,a1 as me,aj as pe,ak as fe,al as _e,am as ke,an as Te,ao as q,ap as ye,aq as Se,ar as be,as as P,at as Le,_ as G,b as h,au as Z,e as ee,O as te,av as ve,aw as ne,ax as ie,ay as we,az as O,aA as Ce,aB as u,aC as Ee,M as j,aD as re,aE as ze,aF as Pe,aG as Ie,aH as xe,aI as Me,aJ as De,aK as Oe,aL as Ae,c as oe,R as je,aM as H,aN as Re,aO as Ne,aP as Fe,aQ as w,aR as $e,aS as Ve,aT as We,aU as Be,aV as se,C as Ge,aW as Ue,aX as qe,S as He}from"./index-BfSJrKL5.js";class Je{constructor(e,t,n){this.id=e,this.dependencies=t,this.callback=n}}var _;(function(d){d[d.Uninitialized=1]="Uninitialized",d[d.InitializedInternal=2]="InitializedInternal",d[d.InitializedExternal=3]="InitializedExternal"})(_||(_={}));const M=class M{constructor(){this._isWebWorker=typeof self=="object"&&self.constructor&&self.constructor.name==="DedicatedWorkerGlobalScope",this._isRenderer=typeof document=="object",this._defineCalls=[],this._state=_.Uninitialized}_initialize(){var e,t;if(this._state===_.Uninitialized){if(globalThis.define){this._state=_.InitializedExternal;return}}else return;this._state=_.InitializedInternal,globalThis.define=(n,i,r)=>{typeof n!="string"&&(r=i,i=n,n=null),(typeof i!="object"||!Array.isArray(i))&&(r=i,i=null),this._defineCalls.push(new Je(n,i,r))},globalThis.define.amd=!0,this._isRenderer?this._amdPolicy=globalThis._VSCODE_WEB_PACKAGE_TTP??((e=window.trustedTypes)==null?void 0:e.createPolicy("amdLoader",{createScriptURL(n){if(n.startsWith(window.location.origin)||n.startsWith(`${ce.vscodeFileResource}://${ge}`))return n;throw new Error(`[trusted_script_src] Invalid script url: ${n}`)}})):this._isWebWorker&&(this._amdPolicy=globalThis._VSCODE_WEB_PACKAGE_TTP??((t=globalThis.trustedTypes)==null?void 0:t.createPolicy("amdLoader",{createScriptURL(n){return n}})))}async load(e){if(this._initialize(),this._state===_.InitializedExternal)return new Promise(s=>{const o=ue();globalThis.define(o,[e],function(a){s(a)})});const t=await(this._isWebWorker?this._workerLoadScript(e):this._isRenderer?this._rendererLoadScript(e):this._nodeJSLoadScript(e));if(!t){console.warn(`Did not receive a define call from script ${e}`);return}const n={},i=[],r=[];if(Array.isArray(t.dependencies))for(const s of t.dependencies)s==="exports"?i.push(n):r.push(s);if(r.length>0)throw new Error(`Cannot resolve dependencies for script ${e}. The dependencies are: ${r.join(", ")}`);return typeof t.callback=="function"?t.callback(...i)??n:t.callback}_rendererLoadScript(e){return new Promise((t,n)=>{const i=document.createElement("script");i.setAttribute("async","async"),i.setAttribute("type","text/javascript");const r=()=>{i.removeEventListener("load",s),i.removeEventListener("error",o)},s=a=>{r(),t(this._defineCalls.pop())},o=a=>{r(),n(a)};i.addEventListener("load",s),i.addEventListener("error",o),this._amdPolicy&&(e=this._amdPolicy.createScriptURL(e)),i.setAttribute("src",e),window.document.getElementsByTagName("head")[0].appendChild(i)})}async _workerLoadScript(e){return this._amdPolicy&&(e=this._amdPolicy.createScriptURL(e)),await import(e).then(t=>t.default??t),this._defineCalls.pop()}async _nodeJSLoadScript(e){try{const t=(await S(()=>import("fs"),[]).then(g=>g.default??g)).default,n=(await S(()=>import("vm"),[]).then(g=>g.default??g)).default,i=(await S(()=>import("module"),[]).then(g=>g.default??g)).default,r=Q.parse(e).fsPath,s=t.readFileSync(r).toString(),o=i.wrap(s.replace(/^#!.*/,""));return new n.Script(o).runInThisContext().apply(),this._defineCalls.pop()}catch(t){throw t}}};M.INSTANCE=new M;let J=M;function Ke(d,e){var s,o,a,c;(c=globalThis._VSCODE_PRODUCT_JSON??((a=(o=(s=globalThis.vscode)==null?void 0:s.context)==null?void 0:o.configuration())==null?void 0:a.product))!=null&&c.commit;const n=`${d}/${e}`,r=`${B}/${n}`;return W.asBrowserUri(r).toString(!0)}class Ye extends C{constructor(e,t,n,i,r,s,o){super(),this._grammar=e,this._initialState=t,this._containsEmbeddedLanguages=n,this._createBackgroundTokenizer=i,this._backgroundTokenizerShouldOnlyVerifyTokens=r,this._reportTokenizationTime=s,this._reportSlowTokenization=o,this._seenLanguages=[],this._onDidEncounterLanguage=this._register(new de),this.onDidEncounterLanguage=this._onDidEncounterLanguage.event}get backgroundTokenizerShouldOnlyVerifyTokens(){return this._backgroundTokenizerShouldOnlyVerifyTokens()}getInitialState(){return this._initialState}tokenize(e,t,n){throw new Error("Not supported!")}createBackgroundTokenizer(e,t){if(this._createBackgroundTokenizer)return this._createBackgroundTokenizer(e,t)}tokenizeEncoded(e,t,n){const i=Math.random()*1e4<1,r=this._reportSlowTokenization||i,s=r?new le(!0):void 0,o=this._grammar.tokenizeLine2(e,n,500);if(r){const c=s.elapsed();(i||c>32)&&this._reportTokenizationTime(c,e.length,i)}if(o.stoppedEarly)return console.warn(`Time limit reached when tokenizing line: ${e.substring(0,100)}`),new U(o.tokens,n);if(this._containsEmbeddedLanguages){const c=this._seenLanguages,g=o.tokens;for(let l=0,m=g.length>>>1;l<m;l++){const A=g[(l<<1)+1],L=he.getLanguageId(A);c[L]||(c[L]=!0,this._onDidEncounterLanguage.fire(L))}}let a;return n.equals(o.ruleStack)?a=n:a=o.ruleStack,new U(o.tokens,a)}}class Qe extends C{get backgroundTokenizerShouldOnlyVerifyTokens(){return this._actual.backgroundTokenizerShouldOnlyVerifyTokens}constructor(e,t,n,i){super(),this._encodedLanguageId=e,this._actual=t,this._maxTokenizationLineLength=i,this._register(X(this._maxTokenizationLineLength)),this._register(n)}getInitialState(){return this._actual.getInitialState()}tokenize(e,t,n){throw new Error("Not supported!")}tokenizeEncoded(e,t,n){return e.length>=this._maxTokenizationLineLength.get()?me(this._encodedLanguageId,n):this._actual.tokenizeEncoded(e,t,n)}createBackgroundTokenizer(e,t){if(this._actual.createBackgroundTokenizer)return this._actual.createBackgroundTokenizer(e,t)}}const v=class v{static getChannel(e){return e.getChannel(v.CHANNEL_NAME)}static setChannel(e,t){e.setChannel(v.CHANNEL_NAME,t)}};v.CHANNEL_NAME="textMateWorkerHost";let N=v;class Xe{constructor(e){this.edits=e.slice().sort(pe(t=>t.offset,fe))}applyToArray(e){for(let t=this.edits.length-1;t>=0;t--){const n=this.edits[t];e.splice(n.offset,n.length,...new Array(n.newLength))}}}class Ze{constructor(e,t,n){this.offset=e,this.length=t,this.newLength=n}toString(){return`[${this.offset}, +${this.length}) -> +${this.newLength}}`}}class I{static fromMany(e){const t=e.map(n=>new I(n));return new et(t)}constructor(e){this.transformation=e,this.idx=0,this.offset=0}transform(e){let t=this.transformation.edits[this.idx];for(;t&&t.offset+t.length<=e;)this.offset+=t.newLength-t.length,this.idx++,t=this.transformation.edits[this.idx];if(!(t&&t.offset<=e))return e+this.offset}}class et{constructor(e){this.transformers=e}transform(e){for(const t of this.transformers){const n=t.transform(e);if(n===void 0)return;e=n}return e}}const D=class D extends C{constructor(e,t,n,i,r,s){super(),this._model=e,this._worker=t,this._languageIdCodec=n,this._backgroundTokenizationStore=i,this._configurationService=r,this._maxTokenizationLineLength=s,this.controllerId=D._id++,this._pendingChanges=[],this._states=new _e,this._loggingEnabled=ke("editor.experimental.asyncTokenizationLogging",!1,this._configurationService),this._register(X(this._loggingEnabled)),this._register(this._model.onDidChangeContent(c=>{this._shouldLog&&console.log("model change",{fileName:this._model.uri.fsPath.split("\\").pop(),changes:R(c.changes)}),this._worker.$acceptModelChanged(this.controllerId,c),this._pendingChanges.push(c)})),this._register(this._model.onDidChangeLanguage(c=>{const g=this._model.getLanguageId(),l=this._languageIdCodec.encodeLanguageId(g);this._worker.$acceptModelLanguageChanged(this.controllerId,g,l)}));const o=this._model.getLanguageId(),a=this._languageIdCodec.encodeLanguageId(o);this._worker.$acceptNewModel({uri:this._model.uri,versionId:this._model.getVersionId(),lines:this._model.getLinesContent(),EOL:this._model.getEOL(),languageId:o,encodedLanguageId:a,maxTokenizationLineLength:this._maxTokenizationLineLength.get(),controllerId:this.controllerId}),this._register(Te(c=>{const g=this._maxTokenizationLineLength.read(c);this._worker.$acceptMaxTokenizationLineLength(this.controllerId,g)}))}dispose(){super.dispose(),this._worker.$acceptRemovedModel(this.controllerId)}requestTokens(e,t){this._worker.$retokenize(this.controllerId,e,t)}async setTokensAndStates(e,t,n,i){if(this.controllerId!==e)return;let r=q.deserialize(new Uint8Array(n));if(this._shouldLog&&console.log("received background tokenization result",{fileName:this._model.uri.fsPath.split("\\").pop(),updatedTokenLines:r.map(o=>o.getLineRange()).join(" & "),updatedStateLines:i.map(o=>new ye(o.startLineNumber,o.startLineNumber+o.stateDeltas.length).toString()).join(" & ")}),this._shouldLog){const o=this._pendingChanges.filter(a=>a.versionId<=t).map(a=>a.changes).map(a=>R(a)).join(" then ");console.log("Applying changes to local states",o)}for(;this._pendingChanges.length>0&&this._pendingChanges[0].versionId<=t;){const o=this._pendingChanges.shift();this._states.acceptChanges(o.changes)}if(this._pendingChanges.length>0){if(this._shouldLog){const c=this._pendingChanges.map(g=>g.changes).map(g=>R(g)).join(" then ");console.log("Considering non-processed changes",c)}const o=I.fromMany(this._pendingChanges.map(c=>K(c.changes))),a=new q;for(const c of r)for(let g=c.startLineNumber;g<=c.endLineNumber;g++)o.transform(g-1)!==void 0&&a.add(g,c.getLineTokens(g));r=a.finalize();for(const c of this._pendingChanges)for(const g of c.changes)for(let l=0;l<r.length;l++)r[l].applyEdit(g.range,g.text)}const s=I.fromMany(this._pendingChanges.map(o=>K(o.changes)));if(!this._applyStateStackDiffFn||!this._initialState){const{applyStateStackDiff:o,INITIAL:a}=await S(async()=>{const{applyStateStackDiff:c,INITIAL:g}=await import("./main-DHcIJauR.js").then(l=>l.m);return{applyStateStackDiff:c,INITIAL:g}},__vite__mapDeps([0,1,2])).then(c=>c.default??c);this._applyStateStackDiffFn=o,this._initialState=a}for(const o of i){let a=o.startLineNumber<=1?this._initialState:this._states.getEndState(o.startLineNumber-1);for(let c=0;c<o.stateDeltas.length;c++){const g=o.stateDeltas[c];let l;g?(l=this._applyStateStackDiffFn(a,g),this._states.setEndState(o.startLineNumber+c,l)):l=this._states.getEndState(o.startLineNumber+c);const m=s.transform(o.startLineNumber+c-1);m!==void 0&&this._backgroundTokenizationStore.setEndState(m+1,l),o.startLineNumber+c>=this._model.getLineCount()-1&&this._backgroundTokenizationStore.backgroundTokenizationFinished(),a=l}}this._backgroundTokenizationStore.setTokens(r)}get _shouldLog(){return this._loggingEnabled.get()}};D._id=0;let F=D;function K(d){return new Xe(d.map(e=>new Ze(e.range.startLineNumber-1,e.range.endLineNumber-e.range.startLineNumber+1,Se(e.text)[0]+1)))}function R(d){return d.map(e=>be.lift(e.range).toString()+" => "+e.text).join(" & ")}var E,k;let $=(k=class{constructor(e,t,n,i,r,s,o,a){this._reportTokenizationTime=e,this._shouldTokenizeAsync=t,this._extensionResourceLoaderService=n,this._configurationService=i,this._languageService=r,this._environmentService=s,this._notificationService=o,this._telemetryService=a,this._workerProxyPromise=null,this._worker=null,this._workerProxy=null,this._workerTokenizerControllers=new Map,this._currentTheme=null,this._currentTokenColorMap=null,this._grammarDefinitions=[]}dispose(){this._disposeWorker()}createBackgroundTokenizer(e,t,n){if(!this._shouldTokenizeAsync()||e.isTooLargeForSyncing())return;const i=new P,r=this._getWorkerProxy().then(s=>{if(i.isDisposed||!s)return;const o={controller:void 0,worker:this._worker};return i.add(tt(e,()=>{const a=new F(e,s,this._languageService.languageIdCodec,t,this._configurationService,n);return o.controller=a,this._workerTokenizerControllers.set(a.controllerId,a),we(()=>{o.controller=void 0,this._workerTokenizerControllers.delete(a.controllerId),a.dispose()})})),o});return{dispose(){i.dispose()},requestTokens:async(s,o)=>{const a=await r;a!=null&&a.controller&&a.worker===this._worker&&a.controller.requestTokens(s,o)},reportMismatchingTokens:s=>{E._reportedMismatchingTokens||(E._reportedMismatchingTokens=!0,this._notificationService.error({message:"Async Tokenization Token Mismatch in line "+s,name:"Async Tokenization Token Mismatch"}),this._telemetryService.publicLog2("asyncTokenizationMismatchingTokens",{}))}}}setGrammarDefinitions(e){this._grammarDefinitions=e,this._disposeWorker()}acceptTheme(e,t){this._currentTheme=e,this._currentTokenColorMap=t,this._currentTheme&&this._currentTokenColorMap&&this._workerProxy&&this._workerProxy.$acceptTheme(this._currentTheme,this._currentTokenColorMap)}_getWorkerProxy(){return this._workerProxyPromise||(this._workerProxyPromise=this._createWorkerProxy()),this._workerProxyPromise}async _createWorkerProxy(){const n=`${`${B}/vscode-oniguruma`}/release/onig.wasm`,i={grammarDefinitions:this._grammarDefinitions,onigurumaWASMUri:W.asBrowserUri(n).toString(!0)},r=this._worker=Le("vs/workbench/services/textMate/browser/backgroundTokenization/worker/textMateTokenizationWorker.worker","TextMateWorker");return N.setChannel(r,{$readFile:async s=>{const o=Q.revive(s);return this._extensionResourceLoaderService.readExtensionResource(o)},$setTokensAndStates:async(s,o,a,c)=>{const g=this._workerTokenizerControllers.get(s);g&&g.setTokensAndStates(s,o,a,c)},$reportTokenizationTime:(s,o,a,c,g)=>{this._reportTokenizationTime(s,o,a,c,g)}}),await r.proxy.$init(i),this._worker!==r?null:(this._workerProxy=r.proxy,this._currentTheme&&this._currentTokenColorMap&&this._workerProxy.$acceptTheme(this._currentTheme,this._currentTokenColorMap),r.proxy)}_disposeWorker(){for(const e of this._workerTokenizerControllers.values())e.dispose();this._workerTokenizerControllers.clear(),this._worker&&(this._worker.dispose(),this._worker=null),this._workerProxy=null,this._workerProxyPromise=null}},E=k,k._reportedMismatchingTokens=!1,k);$=E=G([h(2,Z),h(3,ee),h(4,te),h(5,ve),h(6,ne),h(7,ie)],$);function tt(d,e){const t=new P,n=t.add(new P);function i(){d.isAttachedToEditor()?n.add(e()):n.clear()}return i(),t.add(d.onDidChangeAttached(()=>{i()})),t}class nt{constructor(){this._scopeNameToLanguageRegistration=Object.create(null)}reset(){this._scopeNameToLanguageRegistration=Object.create(null)}register(e){this._scopeNameToLanguageRegistration[e.scopeName]=e}getGrammarDefinition(e){return this._scopeNameToLanguageRegistration[e]||null}}const z="No TM Grammar registered for this language.";class it extends C{constructor(e,t,n,i){super(),this._host=e,this._initialState=n.INITIAL,this._scopeRegistry=new nt,this._injections={},this._injectedEmbeddedLanguages={},this._languageToScope=new Map,this._grammarRegistry=this._register(new n.Registry({onigLib:i,loadGrammar:async r=>{const s=this._scopeRegistry.getGrammarDefinition(r);if(!s)return this._host.logTrace(`No grammar found for scope ${r}`),null;const o=s.location;try{const a=await this._host.readFile(o);return n.parseRawGrammar(a,o.path)}catch(a){return this._host.logError(`Unable to load and parse grammar for scope ${r} from ${o}`,a),null}},getInjections:r=>{const s=r.split(".");let o=[];for(let a=1;a<=s.length;a++){const c=s.slice(0,a).join(".");o=[...o,...this._injections[c]||[]]}return o}}));for(const r of t){if(this._scopeRegistry.register(r),r.injectTo){for(const s of r.injectTo){let o=this._injections[s];o||(this._injections[s]=o=[]),o.push(r.scopeName)}if(r.embeddedLanguages)for(const s of r.injectTo){let o=this._injectedEmbeddedLanguages[s];o||(this._injectedEmbeddedLanguages[s]=o=[]),o.push(r.embeddedLanguages)}}r.language&&this._languageToScope.set(r.language,r.scopeName)}}has(e){return this._languageToScope.has(e)}setTheme(e,t){this._grammarRegistry.setTheme(e,t)}getColorMap(){return this._grammarRegistry.getColorMap()}async createGrammar(e,t){const n=this._languageToScope.get(e);if(typeof n!="string")throw new Error(z);const i=this._scopeRegistry.getGrammarDefinition(n);if(!i)throw new Error(z);const r=i.embeddedLanguages;if(this._injectedEmbeddedLanguages[n]){const a=this._injectedEmbeddedLanguages[n];for(const c of a)for(const g of Object.keys(c))r[g]=c[g]}const s=Object.keys(r).length>0;let o;try{o=await this._grammarRegistry.loadGrammarWithConfiguration(n,t,{embeddedLanguages:r,tokenTypes:i.tokenTypes,balancedBracketSelectors:i.balancedBracketSelectors,unbalancedBracketSelectors:i.unbalancedBracketSelectors})}catch(a){throw a.message&&a.message.startsWith("No grammar provided for")?new Error(z):a}return{languageId:e,grammar:o,initialState:this._initialState,containsEmbeddedLanguages:s,sourceExtensionId:i.sourceExtensionId}}}const f=O.registerExtensionPoint({extensionPoint:"grammars",deps:[Ce],jsonSchema:{description:u(7073,"Contributes textmate tokenizers."),type:"array",defaultSnippets:[{body:[{language:"${1:id}",scopeName:"source.${2:id}",path:"./syntaxes/${3:id}.tmLanguage."}]}],items:{type:"object",defaultSnippets:[{body:{language:"${1:id}",scopeName:"source.${2:id}",path:"./syntaxes/${3:id}.tmLanguage."}}],properties:{language:{description:u(7074,"Language identifier for which this syntax is contributed to."),type:"string"},scopeName:{description:u(7075,"Textmate scope name used by the tmLanguage file."),type:"string"},path:{description:u(7076,"Path of the tmLanguage file. The path is relative to the extension folder and typically starts with './syntaxes/'."),type:"string"},embeddedLanguages:{description:u(7077,"A map of scope name to language id if this grammar contains embedded languages."),type:"object"},tokenTypes:{description:u(7078,"A map of scope name to token types."),type:"object",additionalProperties:{enum:["string","comment","other"]}},injectTo:{description:u(7079,"List of language scope names to which this grammar is injected to."),type:"array",items:{type:"string"}},balancedBracketScopes:{description:u(7080,"Defines which scope names contain balanced brackets."),type:"array",items:{type:"string"},default:["*"]},unbalancedBracketScopes:{description:u(7081,"Defines which scope names do not contain balanced brackets."),type:"array",items:{type:"string"},default:[]}},required:["scopeName","path"]}}});var y,T;let V=(T=class extends C{constructor(e,t,n,i,r,s,o,a,c,g){super(),this._languageService=e,this._themeService=t,this._extensionResourceLoaderService=n,this._notificationService=i,this._logService=r,this._configurationService=s,this._progressService=o,this._environmentService=a,this._instantiationService=c,this._telemetryService=g,this._createdModes=[],this._encounteredLanguages=[],this._debugMode=!1,this._debugModePrintFunc=()=>{},this._grammarDefinitions=null,this._grammarFactory=null,this._tokenizersRegistrations=new P,this._currentTheme=null,this._currentTokenColorMap=null,this._threadedBackgroundTokenizerFactory=this._instantiationService.createInstance($,(l,m,A,L,ae)=>this._reportTokenizationTime(l,m,A,L,!0,ae),()=>this.getAsyncTokenizationEnabled()),this._vscodeOniguruma=null,this._styleElement=Ee(),this._styleElement.className="vscode-tokens-styles",f.setHandler(l=>this._handleGrammarsExtPoint(l)),this._updateTheme(this._themeService.getColorTheme(),!0),this._register(this._themeService.onDidColorThemeChange(()=>{this._updateTheme(this._themeService.getColorTheme(),!1)})),this._register(this._languageService.onDidRequestRichLanguageFeatures(l=>{this._createdModes.push(l)}))}getAsyncTokenizationEnabled(){return!!this._configurationService.getValue("editor.experimental.asyncTokenization")}getAsyncTokenizationVerification(){return!!this._configurationService.getValue("editor.experimental.asyncTokenizationVerification")}_handleGrammarsExtPoint(e){this._grammarDefinitions=null,this._grammarFactory&&(this._grammarFactory.dispose(),this._grammarFactory=null),this._tokenizersRegistrations.clear(),this._grammarDefinitions=[];for(const t of e){const n=t.value;for(const i of n){const r=this._validateGrammarDefinition(t,i);if(r&&(this._grammarDefinitions.push(r),r.language)){const s=new Fe(()=>this._createTokenizationSupport(r.language));this._tokenizersRegistrations.add(s),this._tokenizersRegistrations.add(j.registerFactory(r.language,s))}}}this._threadedBackgroundTokenizerFactory.setGrammarDefinitions(this._grammarDefinitions);for(const t of this._createdModes)j.getOrCreate(t)}_validateGrammarDefinition(e,t){if(!st(e.description.extensionLocation,t,e.collector,this._languageService))return null;const n=re(e.description.extensionLocation,t.path),i=Object.create(null);if(t.embeddedLanguages){const a=Object.keys(t.embeddedLanguages);for(let c=0,g=a.length;c<g;c++){const l=a[c],m=t.embeddedLanguages[l];typeof m=="string"&&this._languageService.isRegisteredLanguageId(m)&&(i[l]=this._languageService.languageIdCodec.encodeLanguageId(m))}}const r=Object.create(null);if(t.tokenTypes){const a=Object.keys(t.tokenTypes);for(const c of a)switch(t.tokenTypes[c]){case"string":r[c]=2;break;case"other":r[c]=0;break;case"comment":r[c]=1;break}}const s=t.language&&this._languageService.isRegisteredLanguageId(t.language)?t.language:void 0;function o(a,c){return!Array.isArray(a)||!a.every(g=>typeof g=="string")?c:a}return{location:n,language:s,scopeName:t.scopeName,embeddedLanguages:i,tokenTypes:r,injectTo:t.injectTo,balancedBracketSelectors:o(t.balancedBracketScopes,["*"]),unbalancedBracketSelectors:o(t.unbalancedBracketScopes,[]),sourceExtensionId:e.description.id}}startDebugMode(e,t){if(this._debugMode){this._notificationService.error(u(3084,"Already Logging."));return}this._debugModePrintFunc=e,this._debugMode=!0,this._debugMode&&this._progressService.withProgress({location:15,buttons:[u(3085,"Stop")]},n=>(n.report({message:u(3086,"Preparing to log TM Grammar parsing. Press Stop when finished.")}),this._getVSCodeOniguruma().then(i=>(i.setDefaultDebugCall(!0),n.report({message:u(3087,"Now logging TM Grammar parsing. Press Stop when finished.")}),new Promise((r,s)=>{})))),n=>{this._getVSCodeOniguruma().then(i=>{this._debugModePrintFunc=()=>{},this._debugMode=!1,i.setDefaultDebugCall(!1),t()})})}_canCreateGrammarFactory(){return!!this._grammarDefinitions}async _getOrCreateGrammarFactory(){if(this._grammarFactory)return this._grammarFactory;const[e,t]=await Promise.all([S(()=>import("./main-DHcIJauR.js").then(i=>i.m),__vite__mapDeps([0,1,2])).then(i=>i.default??i),this._getVSCodeOniguruma()]),n=Promise.resolve({createOnigScanner:i=>t.createOnigScanner(i),createOnigString:i=>t.createOnigString(i)});return this._grammarFactory?this._grammarFactory:(this._grammarFactory=new it({logTrace:i=>this._logService.trace(i),logError:(i,r)=>this._logService.error(i,r),readFile:i=>this._extensionResourceLoaderService.readExtensionResource(i)},this._grammarDefinitions||[],e,n),this._updateTheme(this._themeService.getColorTheme(),!0),this._grammarFactory)}async _createTokenizationSupport(e){if(!this._languageService.isRegisteredLanguageId(e)||!this._canCreateGrammarFactory())return null;try{const t=await this._getOrCreateGrammarFactory();if(!t.has(e))return null;const n=this._languageService.languageIdCodec.encodeLanguageId(e),i=await t.createGrammar(e,n);if(!i.grammar)return null;const r=at("editor.maxTokenizationLineLength",e,-1,this._configurationService),s=new Ye(i.grammar,i.initialState,i.containsEmbeddedLanguages,(a,c)=>this._threadedBackgroundTokenizerFactory.createBackgroundTokenizer(a,c,r),()=>this.getAsyncTokenizationVerification(),(a,c,g)=>{this._reportTokenizationTime(a,e,i.sourceExtensionId,c,!1,g)},!0),o=s.onDidEncounterLanguage(a=>{if(!this._encounteredLanguages[a]){const c=this._languageService.languageIdCodec.decodeLanguageId(a);this._encounteredLanguages[a]=!0,this._languageService.requestBasicLanguageFeatures(c)}});return new Qe(n,s,o,r)}catch(t){return t.message&&t.message===z||ze(t),null}}_updateTheme(e,t){var r;if(!t&&this._currentTheme&&this._currentTokenColorMap&&ot(this._currentTheme.settings,e.tokenColors)&&Pe(this._currentTokenColorMap,e.tokenColorMap))return;this._currentTheme={name:e.label,settings:e.tokenColors},this._currentTokenColorMap=e.tokenColorMap,(r=this._grammarFactory)==null||r.setTheme(this._currentTheme,this._currentTokenColorMap);const n=rt(this._currentTokenColorMap),i=Ie(n);this._styleElement.textContent=i,j.setColorMap(n),this._currentTheme&&this._currentTokenColorMap&&this._threadedBackgroundTokenizerFactory.acceptTheme(this._currentTheme,this._currentTokenColorMap)}async createTokenizer(e){if(!this._languageService.isRegisteredLanguageId(e))return null;const t=await this._getOrCreateGrammarFactory();if(!t.has(e))return null;const n=this._languageService.languageIdCodec.encodeLanguageId(e),{grammar:i}=await t.createGrammar(e,n);return i}_getVSCodeOniguruma(){return this._vscodeOniguruma||(this._vscodeOniguruma=(async()=>{const[e,t]=await Promise.all([S(()=>import("./main-QaSRAa8f.js").then(n=>n.m),__vite__mapDeps([3,1,2])).then(n=>n.default??n),this._loadVSCodeOnigurumaWASM()]);return await e.loadWASM({data:t,print:n=>{this._debugModePrintFunc(n)}}),e})()),this._vscodeOniguruma}async _loadVSCodeOnigurumaWASM(){return xe?await(await fetch(Ke("vscode-oniguruma","release/onig.wasm"))).arrayBuffer():await fetch(W.asBrowserUri(`${B}/vscode-oniguruma/release/onig.wasm`).toString(!0))}_reportTokenizationTime(e,t,n,i,r,s){const o=r?"async":"sync";y.reportTokenizationTimeCounter[o]>50||(y.reportTokenizationTimeCounter[o]===0&&setTimeout(()=>{y.reportTokenizationTimeCounter[o]=0},1e3*60*60),y.reportTokenizationTimeCounter[o]++,this._telemetryService.publicLog2("editor.tokenizedLine",{timeMs:e,languageId:t,lineLength:i,fromWorker:r,sourceExtensionId:n,isRandomSample:s,tokenizationSetting:this.getAsyncTokenizationEnabled()?this.getAsyncTokenizationVerification()?2:1:0}))}},y=T,T.reportTokenizationTimeCounter={sync:0,async:0},T);V=y=G([h(0,te),h(1,Me),h(2,Z),h(3,ne),h(4,De),h(5,ee),h(6,Oe),h(7,Ae),h(8,oe),h(9,ie)],V);function rt(d){const e=[null];for(let t=1,n=d.length;t<n;t++)e[t]=je.fromHex(d[t]);return e}function ot(d,e){if(!e||!d||e.length!==d.length)return!1;for(let t=e.length-1;t>=0;t--){const n=e[t],i=d[t];if(n.scope!==i.scope)return!1;const r=n.settings,s=i.settings;if(r&&s){if(r.fontStyle!==s.fontStyle||r.foreground!==s.foreground||r.background!==s.background)return!1}else if(!r||!s)return!1}return!0}function st(d,e,t,n){if(e.language&&(typeof e.language!="string"||!n.isRegisteredLanguageId(e.language)))return t.error(u(3088,"Unknown language in `contributes.{0}.language`. Provided value: {1}",f.name,String(e.language))),!1;if(!e.scopeName||typeof e.scopeName!="string")return t.error(u(3089,"Expected string in `contributes.{0}.scopeName`. Provided value: {1}",f.name,String(e.scopeName))),!1;if(!e.path||typeof e.path!="string")return t.error(u(3090,"Expected string in `contributes.{0}.path`. Provided value: {1}",f.name,String(e.path))),!1;if(e.injectTo&&(!Array.isArray(e.injectTo)||e.injectTo.some(r=>typeof r!="string")))return t.error(u(3091,"Invalid value in `contributes.{0}.injectTo`. Must be an array of language scope names. Provided value: {1}",f.name,JSON.stringify(e.injectTo))),!1;if(e.embeddedLanguages&&!H(e.embeddedLanguages))return t.error(u(3092,"Invalid value in `contributes.{0}.embeddedLanguages`. Must be an object map from scope name to language. Provided value: {1}",f.name,JSON.stringify(e.embeddedLanguages))),!1;if(e.tokenTypes&&!H(e.tokenTypes))return t.error(u(3093,"Invalid value in `contributes.{0}.tokenTypes`. Must be an object map from scope name to token type. Provided value: {1}",f.name,JSON.stringify(e.tokenTypes))),!1;const i=re(d,e.path);return Re(i,d)||t.warn(u(3094,"Expected `contributes.{0}.path` ({1}) to be included inside extension's folder ({2}). This might make the extension non-portable.",f.name,i.path,d.path)),!0}function at(d,e,t,n){return Ne(i=>n.onDidChangeConfiguration(r=>{r.affectsConfiguration(d,{overrideIdentifier:e})&&i(r)}),()=>n.getValue(d,{overrideIdentifier:e})??t)}const p=Ve(),ct=O.registerExtensionPoint({extensionPoint:"semanticTokenTypes",jsonSchema:{description:u(3095,"Contributes semantic token types."),type:"array",items:{type:"object",properties:{id:{type:"string",description:u(3096,"The identifier of the semantic token type"),pattern:w,patternErrorMessage:u(3097,"Identifiers should be in the form letterOrDigit[_-letterOrDigit]*")},superType:{type:"string",description:u(3098,"The super type of the semantic token type"),pattern:w,patternErrorMessage:u(3099,"Super types should be in the form letterOrDigit[_-letterOrDigit]*")},description:{type:"string",description:u(3100,"The description of the semantic token type")}}}}}),gt=O.registerExtensionPoint({extensionPoint:"semanticTokenModifiers",jsonSchema:{description:u(3101,"Contributes semantic token modifiers."),type:"array",items:{type:"object",properties:{id:{type:"string",description:u(3102,"The identifier of the semantic token modifier"),pattern:w,patternErrorMessage:u(3103,"Identifiers should be in the form letterOrDigit[_-letterOrDigit]*")},description:{type:"string",description:u(3104,"The description of the semantic token modifier")}}}}}),ut=O.registerExtensionPoint({extensionPoint:"semanticTokenScopes",jsonSchema:{description:u(3105,"Contributes semantic token scope maps."),type:"array",items:{type:"object",properties:{language:{description:u(3106,"Lists the languge for which the defaults are."),type:"string"},scopes:{description:u(3107,"Maps a semantic token (described by semantic token selector) to one or more textMate scopes used to represent that token."),type:"object",additionalProperties:{type:"array",items:{type:"string"}}}}}}});class dt{constructor(){function e(t,n,i){if(typeof t.id!="string"||t.id.length===0)return i.error(u(3108,"'configuration.{0}.id' must be defined and can not be empty",n)),!1;if(!t.id.match(w))return i.error(u(3109,"'configuration.{0}.id' must follow the pattern letterOrDigit[-_letterOrDigit]*",n)),!1;const r=t.superType;return r&&!r.match(w)?(i.error(u(3110,"'configuration.{0}.superType' must follow the pattern letterOrDigit[-_letterOrDigit]*",n)),!1):typeof t.description!="string"||t.id.length===0?(i.error(u(3111,"'configuration.{0}.description' must be defined and can not be empty",n)),!1):!0}ct.setHandler((t,n)=>{for(const i of n.added){const r=i.value,s=i.collector;if(!r||!Array.isArray(r)){s.error(u(3112,"'configuration.semanticTokenType' must be an array"));return}for(const o of r)e(o,"semanticTokenType",s)&&p.registerTokenType(o.id,o.description,o.superType)}for(const i of n.removed){const r=i.value;for(const s of r)p.deregisterTokenType(s.id)}}),gt.setHandler((t,n)=>{for(const i of n.added){const r=i.value,s=i.collector;if(!r||!Array.isArray(r)){s.error(u(3113,"'configuration.semanticTokenModifier' must be an array"));return}for(const o of r)e(o,"semanticTokenModifier",s)&&p.registerTokenModifier(o.id,o.description)}for(const i of n.removed){const r=i.value;for(const s of r)p.deregisterTokenModifier(s.id)}}),ut.setHandler((t,n)=>{for(const i of n.added){const r=i.value,s=i.collector;if(!r||!Array.isArray(r)){s.error(u(3114,"'configuration.semanticTokenScopes' must be an array"));return}for(const o of r){if(o.language&&typeof o.language!="string"){s.error(u(3115,"'configuration.semanticTokenScopes.language' must be a string"));continue}if(!o.scopes||typeof o.scopes!="object"){s.error(u(3116,"'configuration.semanticTokenScopes.scopes' must be defined as an object"));continue}for(const a in o.scopes){const c=o.scopes[a];if(!Array.isArray(c)||c.some(g=>typeof g!="string")){s.error(u(3117,"'configuration.semanticTokenScopes.scopes' values must be an array of strings"));continue}try{const g=p.parseTokenSelector(a,o.language);p.registerTokenStyleDefault(g,{scopesToProbe:c.map(l=>l.split(" "))})}catch{s.error(u(3118,"configuration.semanticTokenScopes.scopes': Problems parsing selector {0}.",a))}}}}for(const i of n.removed){const r=i.value;for(const s of r)for(const o in s.scopes){const a=s.scopes[o];try{const c=p.parseTokenSelector(o,s.language);p.registerTokenStyleDefault(c,{scopesToProbe:a.map(g=>g.split(" "))})}catch{}}}})}}var b;let x=(b=class{constructor(e){this.instantiationService=e,this.instantiationService.createInstance(dt)}},b.ID="workbench.contrib.tokenClassificationExtensionPoint",b);x=G([h(0,oe)],x);$e(x.ID,x,1);const Y=new URL("/ui_builder/assets/onig-Du5pRr7Y.wasm",import.meta.url).href;We({"vscode-oniguruma/../onig.wasm":Y,"vs/../../node_modules/vscode-oniguruma/release/onig.wasm":Y});Ue(async d=>{d.get(qe).when(2).then(()=>{He.get(se)})});function ht(){return{...Be(),[se.toString()]:new Ge(V,[],!1)}}export{se as ITextMateTokenizationService,ht as default};
